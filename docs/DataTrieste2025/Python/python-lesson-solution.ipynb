{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mount Google Drive\n",
    "If you're using Google Colab, you need to mount Google Drive and change your working directory as follows:\n",
    "\n",
    "1 - Create a Google drive folder named \"DataTrieste\" at the root of your drive storage.  \n",
    "2 - Download the Python Notebook (`python-lesson-labs.ipynb`) to you computer.  \n",
    "3 - Upload the notebook to the `DataTrieste` folder.  \n",
    "4 - Open the notebook with right click and then select \"Open With\" > \"Google Colaboratory\".  \n",
    "5 - Select the \"Mount Drive\" option at the left panel.  \n",
    "6 - Run the Cell to mount drive.  \n",
    "7 - Change directory to the DataTrieste folder with:  \n",
    "    `%cd /content/drive/MyDrive/DataTrieste`      !!!! DON'T FORGET THE PERCENTAGE SIGN !!!!  \n",
    "8 - In order to check the working directory that you are into use  \n",
    "    `%pwd`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd /content/drive/MyDrive/DataTrieste"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interpreter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Python is an interpreted language which can be used in two ways:\n",
    "\n",
    "\"Interactively\": when you use it as an “advanced calculator” executing one command at a time. To start Python in this mode, execute python on the command line:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "2 + 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Hello World\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"Scripting\" Mode: executing a series of “commands” saved in text file, usually with a .py extension after the name of your file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "python script.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction to variables in Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assigning values to variables\n",
    "One of the most basic things we can do in Python is assign values to variables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"Data Carpentry\"  # An example of assigning a value to a new text variable,\n",
    "                         # also known as a string data type in Python\n",
    "number = 42              # An example of assigning a numeric value, or an integer data type\n",
    "pi_value = 3.1415        # An example of assigning a floating point value (the float data type)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we’ve assigned data to the variables `text`, `number` and `pi_value`, using the assignment operator `=`. To review the value of a variable, we can type the name of the variable into the interpreter and press `Return`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Everything in Python has a type. To get the type of something, we can pass it to the built-in function type:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Type of the text object\n",
    "type(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Type of the number object\n",
    "type(number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Type of the pi_value object\n",
    "type(pi_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The variable `text` is of type `str`, short for “string”. Strings hold sequences of characters, which can be letters, numbers, punctuation or more exotic forms of text (even emoji!).\n",
    "\n",
    "We can also see the value of something using another built-in function, `print`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(number)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This may seem redundant, but in fact it’s the only way to display output in a script."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tip: `print` and `type` are built-in functions in Python."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Operators\n",
    "We can perform mathematical calculations in Python using the basic operators +, -, /, *, %:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "2 + 2  # Addition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "6 * 7  # Multiplication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "2 ** 16  # Power"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "13 % 5  # Modulo/remainder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also use comparison and logic operators: <, >, ==, !=, <=, >= and statements of identity such as and, or, not. The data type returned by this is called a boolean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "3 > 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "True and True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "True or False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "True and False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------------------------------------------\n",
    "# SLIDES\n",
    "------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting help"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = 20\n",
    "help(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display all of the available methods (functions) that are built into a data object\n",
    "dir(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------------------------------------------\n",
    "# SLIDES\n",
    "------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sequences: Lists and Tuples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lists\n",
    "Lists are a common data structure to hold an ordered sequence of elements. Each element can be accessed by an index. Note that Python indexes start with 0 instead of 1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numbers = [1, 2, 3]\n",
    "numbers[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Indentation is very important in Python.\n",
    "for num in numbers:\n",
    "    print(num)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To add elements to the end of a list, we can use the append method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numbers.append(4)\n",
    "print(numbers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To find out what methods are available for an object, we can use the built-in help command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "help(numbers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tuples\n",
    "A tuple is similar to a list in that it’s an ordered sequence of elements. However, tuples can not be changed once created (they are “immutable”). Tuples are created by placing comma-separated values inside parentheses ()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tuples use parentheses\n",
    "a_tuple = (1, 2, 3)\n",
    "another_tuple = ('blue', 'green', 'red')\n",
    "\n",
    "# Note: lists use square brackets\n",
    "a_list = [1, 2, 3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------------------------\n",
    "# CHALLENGE 1 - START\n",
    "---------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tuples vs. Lists"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create some variables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_tuple = (1, 2, 3)\n",
    "another_tuple = ('blue', 'green', 'red')\n",
    "a_list = [1, 2, 3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. What happens when you execute `a_list[1] = 5`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_list[1] = 5\n",
    "a_list\n",
    "# The second value in a_list is replaced with 5."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. What happens when you execute `a_tuple[2] = 5`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_tuple[2] = 5\n",
    "a_tuple\n",
    "# As a tuple is immutable, it does not support item assignment. \n",
    "# Elements in a list can be altered individually."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. What does `type(a_tuple)` tell you about `a_tuple`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(a_tuple)\n",
    "# The function tells you that the variable a_tuple is an object of the class tuple."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. What information does the built-in function `len()` provide? Does it provide the same information on both tuples and lists? Does the `help()` function confirm this?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(a_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(a_tuple)\n",
    "# len() tells us the length of an object. \n",
    "# It works the same for both lists and tuples, \n",
    "# providing us with the number of entries in each case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "help(len)\n",
    "# Lists and tuples are both types of container \n",
    "# i.e. objects that can contain multiple items, \n",
    "# the key difference being that lists are mutable \n",
    "# i.e. they can be modified after they have been created, \n",
    "# while tuples are not: their value cannot be modified, only overwritten."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------------------------\n",
    "# CHALLENGE 1 - END\n",
    "---------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dictionaries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A dictionary is a container that holds pairs of objects - keys and values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "translation = {'one': 'first', 'two': 'second'}\n",
    "translation['one']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dictionaries work a lot like lists - except that you index them with keys. You can think about a key as a name or unique identifier for the value it corresponds to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rev = {'first': 'one', 'second': 'two'}\n",
    "rev['first']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To add an item to the dictionary we assign a value to a new key:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rev['third'] = 'three'\n",
    "rev"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using for loops with dictionaries is a little more complicated. We can do this in two ways:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, value in rev.items():\n",
    "    print(key, '->', value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in rev.keys():\n",
    "    print(key, '->', rev[key])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------------------------\n",
    "# CHALLENGE 2 - START\n",
    "---------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dictionaries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rev = {'first': 'one', 'second': 'two'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. First, print the value of the rev dictionary to the screen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(rev)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Reassign the value that corresponds to the key \"second\" so that it no longer reads “two” but instead 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Option 1\n",
    "rev['second'] = 2\n",
    "\n",
    "# Option 2\n",
    "rev.update({'second': 2})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Print the value of rev to the screen again to see if the value has changed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(rev)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------------------------\n",
    "# CHALLENGE 2 - END\n",
    "---------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining a section of code as a function in Python is done using the \"def\" keyword. For example a function that takes two arguments and returns their sum can be defined as:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_function(a, b):\n",
    "    result = a + b\n",
    "    return result\n",
    "\n",
    "z = add_function(20, 22)\n",
    "print(z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Working With Pandas DataFrames in Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### About Libraries\n",
    "A library in Python contains a set of tools (called functions) that perform tasks on our data. Importing a library is like getting a piece of lab equipment out of a storage locker and setting it up on the bench for use in a project. Once a library is set up, it can be used or called to perform the task(s) it was built to do.\n",
    "\n",
    "One of the best options for working with tabular data in Python is to use the Python Data Analysis Library (a.k.a. Pandas). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading data from GitHub\n",
    "\n",
    "If you're using Google Colab or Jupyter Notebook online, you can either upload the data files from your computer, or you can download them directly from GitHub."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget -O data/tmdb-movies2.csv https://raw.githubusercontent.com/CODATA-RDA-DataScienceSchools/Materials/refs/heads/master/docs/DataTrieste2025/Python/data/tmdb-movies.csv\n",
    "\n",
    "!wget -O data/tmdb-movies-missing2.csv https://raw.githubusercontent.com/CODATA-RDA-DataScienceSchools/Materials/refs/heads/master/docs/DataTrieste2025/Python/data/tmdb-movies-missing.csv\n",
    "\n",
    "!wget -O data/movies2.csv https://raw.githubusercontent.com/CODATA-RDA-DataScienceSchools/Materials/refs/heads/master/docs/DataTrieste2025/Python/data/movies.csv\n",
    "\n",
    "!wget -O data/ratings2.csv https://raw.githubusercontent.com/CODATA-RDA-DataScienceSchools/Materials/refs/heads/master/docs/DataTrieste2025/Python/data/ratings.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading CSV Data Using Pandas "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use Pandas’ read_csv function to pull the file directly into a DataFrame.\n",
    "\n",
    "A DataFrame is a 2-dimensional data structure that can store data of different types (including strings, numbers, categories and more) in columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note that pd.read_csv is used because we imported pandas as pd\n",
    "pd.read_csv(\"data/tmdb-movies.csv\")\n",
    "# The first column is the index of the DataFrame. \n",
    "# The index is used to identify the position of the data, \n",
    "# but it is not an actual column of the DataFrame."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------------------------------------------\n",
    "# SLIDES\n",
    "------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to save the data to memory so we can work with it.\n",
    "To do that, we need to assign the DataFrame to a variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save data to memory\n",
    "my_data = pd.read_csv(\"data/tmdb-movies.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View the data object\n",
    "my_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View the first few lines\n",
    "my_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View object type\n",
    "type(my_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View shape (dimensions)\n",
    "my_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View data types\n",
    "my_data.dtypes\n",
    "# All the values in a single column have the same type.\n",
    "# Some columns cannot contain fractional values\n",
    "# The object type represents strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View info\n",
    "my_data.info()\n",
    "# This shows the type (DataFrame), shape (rows and columns), non-null counts, and dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate summary statistics for all numeric columns\n",
    "my_data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are many ways to summarize and access the data stored in DataFrames, using attributes and methods provided by the DataFrame object.\n",
    "\n",
    "Attributes are features of an object.\n",
    "\n",
    "Methods are like functions, but they only work on particular kinds of objects. With a method, we can supply extra information in the parentheses to control behaviour."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------------------------\n",
    "# CHALLENGE 3 - START\n",
    "---------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataframes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using our DataFrame `my_data`, try out the attributes & methods below to see what they return."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# Note: Update the relative path to the data\n",
    "my_data = pd.read_csv(\"data/tmdb-movies.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_data.columns\n",
    "# provides the names of the columns in the DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_data.shape\n",
    "# provides the dimensions of the DataFrame as a tuple in (r,c) format, where r is the number of rows and c the number of columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_data.head() # returns first 5 lines\n",
    "my_data.head(15) # returns 15 lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_data.tail() # returns last 5 lines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------------------------\n",
    "# CHALLENGE 3 - END\n",
    "---------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let’s perform some quick summary statistics to learn more about the data that we’re working with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View columns\n",
    "my_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View unique directors\n",
    "\n",
    "# Option 1 - view names\n",
    "pd.unique(my_data['director'])\n",
    "\n",
    "# Option 2 - view total number of unique directors\n",
    "director_names = my_data['director']\n",
    "unique_directors = pd.unique(director_names)\n",
    "number_unique_directors = len(unique_directors)\n",
    "print(number_unique_directors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------------------------\n",
    "# CHALLENGE 4 - START\n",
    "---------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# Note: Update the relative path to the data\n",
    "my_data = pd.read_csv(\"data/tmdb-movies.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Create a list of unique directors `(\"director\")` found in the data. Call it `unique_directors`. How many unique directors are there in the data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Option 1\n",
    "unique_directors = pd.unique(my_data['director'])\n",
    "len(unique_directors)\n",
    "\n",
    "# Option 2\n",
    "len(pd.unique(my_data['director']))\n",
    "# Answer: 5051 unique directors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. What is the difference between `len(unique_directors)` and `my_data['director'].nunique()`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(unique_directors)\n",
    "# Returns 5051\n",
    "# Also counts missing/null values as a \"unique director\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_data['director'].nunique()\n",
    "\n",
    "# Returns 5050\n",
    "# Ignores the null values and gives the true number of unique directors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------------------------\n",
    "# CHALLENGE 4 - END\n",
    "---------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------------------------------------------\n",
    "# SLIDES\n",
    "------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Groups in Pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We often want to calculate summary statistics grouped by subsets or attributes within fields of our data.\n",
    "\n",
    "We can calculate basic statistics for all records in a single column using the syntax below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_data['revenue'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also extract one specific metric if we wish:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_data['revenue'].min()\n",
    "my_data['revenue'].max()\n",
    "my_data['revenue'].mean()\n",
    "my_data['revenue'].std()\n",
    "my_data['revenue'].count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But if we want to summarize by one or more variables, we can use Pandas’ `.groupby` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group data by director\n",
    "grouped_data = my_data.groupby('director')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary statistics for all numeric columns by director\n",
    "grouped_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Provide the mean for each numeric column by director\n",
    "grouped_data.mean(numeric_only=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------------------------\n",
    "# CHALLENGE 5 - START\n",
    "---------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# Note: Update the relative path to the data\n",
    "my_data = pd.read_csv(\"data/tmdb-movies.csv\")\n",
    "grouped_data = my_data.groupby('release_year')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. How many movies were released per year?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. What happens when you group by two columns using the following syntax and then calculate mean values?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_data2 = my_data.groupby(['release_year', 'director'])\n",
    "grouped_data2.mean(numeric_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can specify particular columns and particular summary statistics using the agg() method (short for aggregate)\n",
    "my_data.groupby(['release_year', 'director']).agg({\"budget\": 'max',\n",
    "                                                  \"runtime\": 'median',\n",
    "                                                  \"revenue\": 'mean'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Summarize revenue values for each year in your data. HINT: you can use the following syntax to only create summary statistics for one column in your data. `my_data['release_year'].describe()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_data.groupby(['release_year'])['revenue'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------------------------\n",
    "# CHALLENGE 5 - END\n",
    "---------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let’s next count the number of movies for each year. We’ll use `groupby` combined with a `count()` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_counts = my_data.groupby('release_year')['id'].count()\n",
    "print(movie_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also count just the rows that have the genre \"Thriller\":"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_data.groupby('genres')['release_year'].count()['Thriller']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quick & Easy Plotting Data Using Pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can plot our summary stats using Pandas, too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure figures appear inline in Ipython Notebook\n",
    "%matplotlib inline\n",
    "# Create a quick bar chart\n",
    "movie_counts.plot(kind='bar');\n",
    "# The ; just removes the object type displayed at the top"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------------------------\n",
    "# CHALLENGE 6 - START\n",
    "---------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import pandas as pd\n",
    "# Note: Update the relative path to the data\n",
    "my_data = pd.read_csv(\"data/tmdb-movies.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Create a plot of average runtime from year to year."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_data.groupby('release_year')['runtime'].mean().plot(kind='bar')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Create a plot of the average popularity of movies for each year."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Option 1\n",
    "my_data.groupby('release_year')['popularity'].mean().plot(kind='bar')\n",
    "\n",
    "# Option 2\n",
    "grouped_pop = my_data.groupby('release_year')['popularity'].mean()\n",
    "grouped_pop.plot(kind='bar');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------------------------\n",
    "# CHALLENGE 6 - END\n",
    "---------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------------------------------------------\n",
    "# SLIDES\n",
    "------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Indexing and Slicing in Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We often want to work with subsets of a DataFrame object. There are different ways to accomplish this including: using labels (column headings), numeric ranges, or specific x,y index locations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selecting data using Labels (Column Headings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use square brackets [] to select a subset of a Python object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TIP: use the .head() method we saw earlier to make output shorter\n",
    "# Method 1: select a 'subset' of the data using the column name\n",
    "my_data['original_title'].head()\n",
    "\n",
    "# Method 2: use the column name as an 'attribute'; gives the same output\n",
    "my_data.original_title.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also create a new object that contains only the data within the `original_title` column as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creates an object, movie_titles, that only contains the `original_title` column\n",
    "movie_titles = my_data['original_title']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can pass a list of column names too, as an index to select columns in that order. This is useful when we need to reorganize our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the director and release_year columns from the DataFrame\n",
    "my_data[['director', 'release_year']]\n",
    "\n",
    "# What happens when you flip the order?\n",
    "my_data[['release_year', 'director']]\n",
    "\n",
    "# What happens if you ask for a column that doesn't exist?\n",
    "my_data['rating']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracting Range based Subsets: Slicing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Python uses 0-based indexing. This means that the first element in an object is located at position 0. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list of numbers\n",
    "a = [1, 2, 3, 4, 5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Indexing: getting a specific element\n",
    "a[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Slicing: selecting a set of elements\n",
    "a[1:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------------------------\n",
    "# CHALLENGE 7 - START\n",
    "---------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extracting data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list of numbers:\n",
    "a = [1, 2, 3, 4, 5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. What value does the code below return?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a[0]\n",
    "# Returns the value 1 (i.e. the first element)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. How about this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a[5]\n",
    "# Raises and IndexError"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. In the example above, calling `a[5]` returns an error. Why is that?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The error is raised because the list `a` has no element with index 5: it has only five entries, indexed from 0 to 4."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. What about?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a[len(a)]\n",
    "# Also raises an IndexError. \n",
    "# len(a) returns 5, making a[len(a)] equivalent to a[5].\n",
    "# To retrieve the final element of a list, use the index -1, \n",
    "# e.g. a[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------------------------\n",
    "# CHALLENGE 7 - END\n",
    "---------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Slicing Subsets of Rows and Columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Slicing using the `[]` operator selects a set of rows and/or columns from a DataFrame. To slice out a set of rows, you use the following syntax: `data[start:stop]`.\n",
    "\n",
    "When slicing in pandas the start bound is included in the output. The stop bound is one step BEYOND the row you want to select. So if you want to select rows 0, 1 and 2 your code would look like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select rows 0, 1, 2 (row 3 is not selected)\n",
    "my_data[0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the first 5 rows (rows 0, 1, 2, 3, 4)\n",
    "my_data[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the last element in the list\n",
    "# (the slice starts at the last element, and ends at the end of the list)\n",
    "my_data[-1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Copying Objects vs Referencing Objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using the 'copy()' method makes a true copy of the data\n",
    "true_copy_data = my_data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using the '=' operator only references the original data\n",
    "ref_data = my_data\n",
    "\n",
    "# If you change any values in `ref_data`,\n",
    "# it will also change in `my_data`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Subsetting Data using Criteria"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can select specific ranges of our data in both the row and column directions using either label or integer-based indexing.\n",
    "\n",
    "`iloc` is primarily an integer-based indexing counting from 0. That is, you specify rows and columns giving a number. Thus, the first row is row 0, the second column is column 1, etc.\n",
    "\n",
    "`loc` is primarily a label-based indexing where you can refer to rows and columns by their name. E.g., column `year`. Note that integers may be used, but they are interpreted as a label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# iloc[row slicing, column slicing]\n",
    "my_data.iloc[0:3, 1:4]\n",
    "\n",
    "# This returned 3 rows of data. When you ask for 0:3, \n",
    "# you are actually telling Python to start at index 0 \n",
    "# and select rows 0, 1, 2 up to but not including 3. We\n",
    "# are selecting columns 1, 2, 3 (not including 4)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loc[row slicing, column slicing]\n",
    "my_data.loc[0:3, 1:4]\n",
    "# This gives an error, because pandas can't find \n",
    "# columns named \"1\", \"2\", \"3\", or \"4\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When using `loc`, integers can be used, but the integers refer to the index label and not the position. For example, using `loc` and selecting 0:3 will get a different result than using `iloc` to select rows 0:3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_data.loc[0:3, ['imdb_id', 'popularity', 'budget']]\n",
    "# We have to use LABELS with LOC.\n",
    "# But do you see the difference in the number of rows? \n",
    "# It extracted the rows at index 0,1,2 AND 3, because it's using the\n",
    "# index as a LABEL, and not using it as a positional argument.\n",
    "\n",
    "# And remember that the start and stop bounds of loc are included."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select all columns for rows of index values 0 and 10\n",
    "my_data.loc[[0, 10], :]\n",
    "\n",
    "# With loc, both the start bound and the stop bound are inclusive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What does this do?\n",
    "my_data.loc[0, ['release_year', 'director', 'budget']]\n",
    "\n",
    "# Note that labels must be found in the DataFrame or you will get a KeyError."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# What happens when you run the code below?\n",
    "my_data.loc[[0, 10, 3549], :]\n",
    "\n",
    "# With loc, both the start bound and the stop bound are inclusive."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also select a specific data value using a row and column location within the DataFrame and iloc indexing:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Syntax for iloc indexing to finding a specific data element:\n",
    "\n",
    "`data.iloc[row, column]`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Subsetting Data using Criteria"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also select a subset of our data using criteria. Let's select all the movies that were released in 2005."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_data[my_data.release_year == 2005]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or we can select all rows that do not contain the year 2005:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Option 1\n",
    "my_data[my_data != 2005]\n",
    "\n",
    "# Option 2\n",
    "my_data[~(my_data == 2005)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can define sets of criteria too:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_data[(my_data.release_year >= 2000) & (my_data.release_year <= 2005)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------------------------\n",
    "# CHALLENGE 8 - START\n",
    "---------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# Note: Update the relative path to the data\n",
    "my_data = pd.read_csv(\"data/tmdb-movies.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Select a subset of rows in the `my_data` DataFrame that contains data from the `release_year` 1999 and that contain `runtime` values less than or equal to 120. How many rows did you end up with? What did your neighbor get?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_data[(my_data.release_year == 1999) & (my_data.runtime <= 120)]\n",
    "len(my_data[(my_data.release_year == 1999) & (my_data.runtime <= 120)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. You can use the `isin` command in Python to query a DataFrame based upon a list of values as follows:\n",
    "\n",
    "my_data[my_data['original_title'].isin([listGoesHere])]\n",
    "\n",
    "Use the `isin` function to find a list of all movies that contain particular genres (\"Comedy\" and \"Thriller\") in the DataFrame. How many records contain these values?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(my_data[my_data['genres'].isin(['Comedy', 'Thriller'])])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a query that finds all rows with a runtime value greater than or equal to 300."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Option 1\n",
    "my_data[my_data[\"runtime\"] >= 300]\n",
    "\n",
    "# Option 2\n",
    "my_data[my_data.runtime >= 300]\n",
    "\n",
    "# Option 3\n",
    "my_data.query(\"runtime >= 300\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `~` symbol in Python can be used to return the OPPOSITE of the selection that you specify. It is equivalent to `is not in`. Write a query that selects all rows with `genres` NOT equal to `Documentary` or `Horror` in the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_data[~my_data[\"genres\"].isin(['Documentary', 'Horror'])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------------------------\n",
    "# CHALLENGE 8 - END\n",
    "---------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using masks to identify a specific condition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A mask can be useful to locate where a particular subset of values exist or don’t exist - for example, NaN, or “Not a Number” values. To understand masks, we also need to understand BOOLEAN objects in Python.\n",
    "\n",
    "Boolean values include `True` or `False`. For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set x to 5\n",
    "x = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What does the code below return?\n",
    "x > 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How about this?\n",
    "x == 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Missing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "my_data_missing = pd.read_csv(\"data/tmdb-movies-missing.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let’s try this out. Let’s identify all locations in the data that have null (missing or NaN) data values. We can use the `isnull` method to do this. The `isnull` method will compare each cell with a null value. If an element has a null value, it will be assigned a value of `True` in the output object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.isnull(my_data_missing)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To select the rows where there are null values, we can use the mask as an index to subset our data as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To select just the rows with NaN values, we can use the 'any()' method\n",
    "\n",
    "my_data_missing[pd.isnull(my_data_missing).any(axis=1)]\n",
    "# axis=1 means that it checks across each row."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can run `isnull` on a particular column too. What does the code below do?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What does this do?\n",
    "missing_titles = my_data_missing[pd.isnull(my_data_missing['original_title'])]\n",
    "print(missing_titles)\n",
    "\n",
    "# We are asking Python to select rows that have a NaN value of title, i.e. missing titles."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's extract the homepages for the movies with missing titles:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_titles['homepage']\n",
    "\n",
    "# You can visit the homepages to get the movie titles."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking the format of our data "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The format of individual columns and rows will impact analysis performed on a dataset read into a pandas DataFrame. For example, you can’t perform mathematical calculations on a string (text formatted data).\n",
    "\n",
    "- Every value has a type.\n",
    "- Use the built-in function type to find the type of a value.\n",
    "- Types control what operations can be done on values.\n",
    "- Strings can be added and multiplied.\n",
    "- Strings have a length (but numbers don’t).\n",
    "- Must convert numbers to strings or vice versa when operating on them.\n",
    "- Can mix integers and floats freely in operations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Types of Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_data['director'].dtype\n",
    "\n",
    "# A type \"O\" stands for \"object\", i.e. string/text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Working With Integers and Floats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we divide one integer by another, we get a float."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(5/9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also convert a floating point number to an integer or an integer to floating point number. Notice that Python by default rounds down when it converts from floating point to integer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert a to an integer\n",
    "a = 7.83\n",
    "int(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert b to a float\n",
    "b = 7\n",
    "float(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Working With Our Movies Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the id field from an integer to a float\n",
    "my_data['id'] = my_data['id'].astype('float64')\n",
    "my_data['id'].dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------------------------\n",
    "# CHALLENGE 9 - START\n",
    "---------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Changing Types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# Note: Update the relative path to the data\n",
    "my_data_missing = pd.read_csv(\"data/tmdb-movies-missing.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Try converting the column `runtime` to floats."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_data_missing['runtime'].astype(\"float\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Convert the `budget` variable to an integer. What goes wrong here? What is pandas telling you?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_data_missing['budget'].astype(\"int\")\n",
    "my_data_missing\n",
    "\n",
    "# IntCastingNaNError\n",
    "# Pandas cannot convert types from float to int if the column contains NaN values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Try to remove the missing values from the `budget` column using `isnull` or `isna()` with `~` (i.e. only keep values that are not null) and convert it to integers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Option 1\n",
    "budget_complete = my_data_missing[~(my_data_missing['budget'].isnull())]\n",
    "budget_complete['budget'].astype('int')\n",
    "\n",
    "# Option 2\n",
    "budget_complete = my_data_missing[~(my_data_missing['budget'].isna())]\n",
    "budget_complete['budget'].astype('int')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------------------------\n",
    "# CHALLENGE 9 - END\n",
    "---------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Missing Data Values - NaN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NaN (Not a Number) values are undefined values that cannot be represented mathematically. pandas, for example, will read an empty cell in a CSV or Excel sheet as NaN."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NaNs have some desirable properties: if we were to average the `budget` column without replacing our NaNs, Python would know to skip over those cells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_data_missing['budget'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dealing with missing data values is always a challenge.\n",
    "\n",
    "It’s sometimes hard to know why values are missing:\n",
    "- Was it because of a data entry error?\n",
    "- Or data that someone was unable to collect?\n",
    "- Should the value be 0? \n",
    "\n",
    "We need to know how missing values are represented in the dataset in order to make good decisions. If we’re lucky, we have some metadata that will tell us more about how null values were handled."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can figure out how many rows contain NaN values for `popularity`. We can also create a new subset from our data that only contains rows with popularity > 0 (i.e., select meaningful values):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(my_data_missing[my_data_missing['popularity'].isna()])\n",
    "\n",
    "# How many rows have popularity values?\n",
    "len(my_data_missing[my_data_missing['popularity'] > 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can replace all `NaN` values with zeroes using the `fillna()` method (after making a copy of the data so we don’t lose our work):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = my_data_missing.copy()\n",
    "# Fill all NaN values with 0\n",
    "df1['popularity'] = df1['popularity'].fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However NaN and 0 yield different analysis results. The mean value when NaN values are replaced with 0 is different from when NaN values are simply thrown out or ignored."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1['popularity'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can fill NaN values with any value that we choose. The code below fills all NaN values with a mean for all popularity values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1['popularity'] = df1['popularity'].fillna(df1['popularity'].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------------------------\n",
    "# CHALLENGE 10 - START\n",
    "---------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Counting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# Note: Update the relative path to the data\n",
    "my_data_missing = pd.read_csv(\"data/tmdb-movies-missing.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Count the number of missing values per column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                         5\n",
       "imdb_id                   13\n",
       "popularity                 3\n",
       "budget                     2\n",
       "revenue                    1\n",
       "original_title             3\n",
       "cast                      76\n",
       "homepage                7904\n",
       "director                  45\n",
       "tagline                 2814\n",
       "keywords                1489\n",
       "overview                   4\n",
       "runtime                    0\n",
       "genres                    23\n",
       "production_companies    1021\n",
       "release_date               0\n",
       "vote_count                 0\n",
       "vote_average               0\n",
       "release_year               0\n",
       "budget_adj                 0\n",
       "revenue_adj                0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Option 1\n",
    "my_data_missing.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Option 2\n",
    "for c in my_data_missing.columns:\n",
    "    print(c, len(my_data_missing[my_data_missing[c].isna()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Option 3\n",
    "for c in my_data_missing.columns:\n",
    "    print(c, len(my_data_missing[pd.isnull(my_data_missing[c])]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------------------------\n",
    "# CHALLENGE 10 - END\n",
    "---------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Writing Out Data to CSV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let’s reload the data so we’re not mixing up all of our previous manipulations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_data = pd.read_csv(\"data/tmdb-movies.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let’s drop all the rows that contain missing values. We will use the command `dropna`. By default, `dropna` removes rows that contain missing data for even just one column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_na = my_data.dropna()\n",
    "\n",
    "# Note: If you want to drop rows with missing values in a specific column:\n",
    "# df_na = my_data.dropna(subset=['popularity'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Export a DataFrame in CSV format and save it in the `data_output` directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write DataFrame to CSV\n",
    "df_na.to_csv('data_output/movies_complete.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------------------------------------------\n",
    "# SLIDES\n",
    "------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Concatenating DataFrames"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We often need to combine data files into a single DataFrame to analyse the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use the `concat` function in pandas to append either columns or rows from one DataFrame to another. Let's create two subsets of data first:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in first 10 lines of table\n",
    "data_sub = my_data.head(10)\n",
    "\n",
    "# Grab the last 10 rows\n",
    "data_sub_last10 = my_data.tail(10)\n",
    "\n",
    "# Reset the index values so the second dataframe appends properly\n",
    "data_sub_last10 = data_sub_last10.reset_index(drop=True)\n",
    "\n",
    "# drop=True option avoids adding new index column with old index values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we concatenate DataFrames, we need to specify the axis:\n",
    "- `axis=0` will stack the second DataFrame UNDER the first one. Columns need to have the same name and data type.\n",
    "- `axis=1` will stack the columns in the second DataFrame to the RIGHT of the first DataFrame. Rows need to be related."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stack the DataFrames on top of each other\n",
    "vertical_stack = pd.concat([data_sub, data_sub_last10], axis=0)\n",
    "vertical_stack\n",
    "\n",
    "# Note that the row indexes for the two dataframes have been repeated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reindex the new DataFrame using the reset_index() method\n",
    "vertical_stack = vertical_stack.reset_index(drop=True)\n",
    "vertical_stack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write DataFrame to CSV\n",
    "vertical_stack.to_csv('data_output/out2.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Place the DataFrames side by side\n",
    "horizontal_stack = pd.concat([data_sub, data_sub_last10], axis=1)\n",
    "horizontal_stack"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Joining DataFrames"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we concatenated our DataFrames, we simply added them to each other - stacking them either vertically or side by side. Another way to combine DataFrames is to use columns in each dataset that contain common values (a common unique identifier).\n",
    "\n",
    "The columns containing the common values are called “join key(s)”. Joining DataFrames in this way is often useful when one DataFrame is a “lookup table” containing additional data that we want to include in the other."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------------------------------------------\n",
    "# SLIDES\n",
    "------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import multiple data files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Many functions in Python have a set of options that can be set by the user if needed. Let's tell pandas to assign empty values in our CSV to NaN with the parameters `keep_default_na=False` and `na_values=[\"\"]`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies = pd.read_csv(\"data/movies.csv\",\n",
    "                   keep_default_na=False,\n",
    "                   na_values=[\"\"])\n",
    "\n",
    "movies.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings = pd.read_csv(\"data/ratings.csv\",\n",
    "                   keep_default_na=False,\n",
    "                   na_values=[\"\"])\n",
    "\n",
    "ratings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Identifying join keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In our example, the join key is the `movieId` column. If you have big data sets, it's easier to identify join keys programmatically:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies.columns[movies.columns.isin(ratings.columns)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Types of joins\n",
    "\n",
    "#### Inner join\n",
    "- Returns a new DataFrame that contains only those rows that have matching values in both of the original DataFrames.\n",
    "- `merged_inner = pd.merge(left=df1, right=df2, left_on='col1', right_on='col2')`\n",
    "\n",
    "#### Left join\n",
    "- Returns all of the rows from the left DataFrame, even those rows whose join key(s) do not have values in the right DataFrame.\n",
    "- `merged_left = pd.merge(left=df1, right=df2, left_on='col1', right_on='col2', how='left')`\n",
    "\n",
    "#### Right join\n",
    "- Returns all of the rows from the right DataFrame, even those rows whose join key(s) do not have values in the left DataFrame.\n",
    "- `merged_right = pd.merge(left=df1, right=df2, left_on='col1', right_on='col2', how='right')`\n",
    "\n",
    "#### Full (outer) join\n",
    "- Returns all pairwise combinations of rows from both DataFrames.\n",
    "- `merged_outer = pd.merge(left=df1, right=df2, left_on='col1', right_on='col2', how='outer')`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inner join\n",
    "\n",
    "# Option 1\n",
    "merged_inner = pd.merge(left=movies, right=ratings, left_on='movieId', right_on='movieId')\n",
    "\n",
    "# Option 2\n",
    "merged_inner = pd.merge(left=movies, right=ratings, on='movieId')\n",
    "\n",
    "merged_inner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Left join\n",
    "merged_left = pd.merge(left=movies, right=ratings, on='movieId', how='left')\n",
    "merged_left"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Right join\n",
    "merged_right = pd.merge(left=movies, right=ratings, on='movieId', how='right')\n",
    "merged_right"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Full (outer) join\n",
    "merged_outer = pd.merge(left=movies, right=ratings, on='movieId', how='outer')\n",
    "merged_outer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------------------------------------------\n",
    "# SLIDES\n",
    "------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Plotting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create a copy of our `merged_inner` data and make some plots with that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_complete = merged_inner.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot data directly from a Pandas dataframe\n",
    "myplot = data_complete['rating'].plot(kind='hist')\n",
    "myplot.set_title('Distribution of Movie Ratings')\n",
    "myplot.set_xlabel('Rating')\n",
    "myplot.set_ylabel('Frequency')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.hist(data_complete['rating'], bins=5, color='skyblue', edgecolor='black')\n",
    "plt.title('Distribution of Movie Ratings')\n",
    "plt.xlabel('Rating')\n",
    "plt.ylabel('Frequency')\n",
    "\n",
    "# Save the plot before showing it\n",
    "plt.savefig('fig_output/matplotlib_histogram.png', dpi=300, bbox_inches='tight')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Seaborn\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.histplot(data_complete['rating'], bins=5, color='skyblue', kde=False)\n",
    "plt.title('Distribution of Movie Ratings')\n",
    "plt.xlabel('Rating')\n",
    "plt.ylabel('Frequency')\n",
    "\n",
    "# Save the plot before showing it\n",
    "plt.savefig('fig_output/seaborn_histogram.png', dpi=300, bbox_inches='tight')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Plotnine\n",
    "from plotnine import ggplot, aes, geom_histogram, ggtitle, labs, theme_classic\n",
    "\n",
    "plot = (ggplot(data_complete, aes(x='rating')) +\n",
    "        geom_histogram(bins=5, fill='skyblue', color='black') +\n",
    "        ggtitle('Distribution of Movie Ratings') +\n",
    "        labs(x='Rating', y='Frequency') +\n",
    "        theme_classic())\n",
    "        \n",
    "print(plot)\n",
    "\n",
    "# Save the plot\n",
    "plot.save('fig_output/plotnine_histogram.png', dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These examples provide the same output visually but differ significantly in the way they are coded. The choice between them depends on the user's preference for customisation, simplicity, and familiarity with the plotting paradigm.\n",
    "\n",
    "#### Summary of Differences\n",
    "\n",
    "**Matplotlib:**\n",
    "\n",
    "- Requires more boilerplate code (e.g., `plt.figure()`, `plt.show()`).\n",
    "- Customisation (color, labels) is done through method arguments.\n",
    "- The histogram is created using `plt.hist()`.\n",
    "\n",
    "**Seaborn:**\n",
    "\n",
    "- Less code than Matplotlib, with some additional aesthetics by default.\n",
    "- Histogram created with `sns.histplot()`; `kde=False` disables the kernel density estimate line.\n",
    "- Integrates with Matplotlib for underlying plotting but adds simplicity.\n",
    "\n",
    "**Plotnine:**\n",
    "\n",
    "- Follows a declarative style with the *Grammar of Graphics* approach.\n",
    "- Plots are constructed by layering components (`ggplot`, `aes`, `geom_histogram`).\n",
    "- Requires fewer explicit function calls for titles and labels but uses a more complex syntax."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------------------------------------------\n",
    "# SLIDES\n",
    "------------------------------------------------------"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
