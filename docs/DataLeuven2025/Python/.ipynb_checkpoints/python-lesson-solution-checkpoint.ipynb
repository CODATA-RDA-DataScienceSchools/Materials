{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interpreter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Python is an interpreted language which can be used in two ways:\n",
    "\n",
    "\"Interactively\": when you use it as an “advanced calculator” executing one command at a time. To start Python in this mode, execute python on the command line:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "2 + 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Hello World\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"Scripting\" Mode: executing a series of “commands” saved in text file, usually with a .py extension after the name of your file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "python my_script.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction to variables in Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assigning values to variables\n",
    "One of the most basic things we can do in Python is assign values to variables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"Data Carpentry\"  # An example of assigning a value to a new text variable,\n",
    "                         # also known as a string data type in Python\n",
    "number = 42              # An example of assigning a numeric value, or an integer data type\n",
    "pi_value = 3.1415        # An example of assigning a floating point value (the float data type)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we’ve assigned data to the variables `text`, `number` and `pi_value`, using the assignment operator `=`. To review the value of a variable, we can type the name of the variable into the interpreter and press `Return`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Everything in Python has a type. To get the type of something, we can pass it to the built-in function type:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Type of the text object\n",
    "type(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Type of the number object\n",
    "type(number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Type of the pi_value object\n",
    "type(pi_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The variable `text` is of type `str`, short for “string”. Strings hold sequences of characters, which can be letters, numbers, punctuation or more exotic forms of text (even emoji!).\n",
    "\n",
    "We can also see the value of something using another built-in function, `print`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(number)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This may seem redundant, but in fact it’s the only way to display output in a script."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tip: `print` and `type` are built-in functions in Python."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Operators\n",
    "We can perform mathematical calculations in Python using the basic operators +, -, /, *, %:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "2 + 2  # Addition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "6 * 7  # Multiplication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "2 ** 16  # Power"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "13 % 5  # Modulo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also use comparison and logic operators: <, >, ==, !=, <=, >= and statements of identity such as and, or, not. The data type returned by this is called a boolean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "3 > 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "True and True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "True or False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "True and False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------------------------------------------\n",
    "# SLIDES\n",
    "------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting help"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = 20\n",
    "help(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display all of the available methods (functions) that are built into a data object\n",
    "dir(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------------------------------------------\n",
    "# SLIDES\n",
    "------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sequences: Lists and Tuples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lists\n",
    "Lists are a common data structure to hold an ordered sequence of elements. Each element can be accessed by an index. Note that Python indexes start with 0 instead of 1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numbers = [1, 2, 3]\n",
    "numbers[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Indentation is very important in Python.\n",
    "for num in numbers:\n",
    "    print(num)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To add elements to the end of a list, we can use the append method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numbers.append(4)\n",
    "print(numbers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To find out what methods are available for an object, we can use the built-in help command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "help(numbers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tuples\n",
    "A tuple is similar to a list in that it’s an ordered sequence of elements. However, tuples can not be changed once created (they are “immutable”). Tuples are created by placing comma-separated values inside parentheses ()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tuples use parentheses\n",
    "a_tuple = (1, 2, 3)\n",
    "another_tuple = ('blue', 'green', 'red')\n",
    "\n",
    "# Note: lists use square brackets\n",
    "a_list = [1, 2, 3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------------------------\n",
    "# CHALLENGE 1\n",
    "---------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dictionaries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A dictionary is a container that holds pairs of objects - keys and values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "translation = {'one': 'first', 'two': 'second'}\n",
    "translation['one']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dictionaries work a lot like lists - except that you index them with keys. You can think about a key as a name or unique identifier for the value it corresponds to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rev = {'first': 'one', 'second': 'two'}\n",
    "rev['first']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To add an item to the dictionary we assign a value to a new key:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rev['third'] = 'three'\n",
    "rev"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using for loops with dictionaries is a little more complicated. We can do this in two ways:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, value in rev.items():\n",
    "    print(key, '->', value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in rev.keys():\n",
    "    print(key, '->', rev[key])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------------------------\n",
    "# CHALLENGE 2\n",
    "---------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining a section of code as a function in Python is done using the def keyword. For example a function that takes two arguments and returns their sum can be defined as:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_function(a, b):\n",
    "    result = a + b\n",
    "    return result\n",
    "\n",
    "z = add_function(20, 22)\n",
    "print(z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Working With Pandas DataFrames in Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### About Libraries\n",
    "A library in Python contains a set of tools (called functions) that perform tasks on our data. Importing a library is like getting a piece of lab equipment out of a storage locker and setting it up on the bench for use in a project. Once a library is set up, it can be used or called to perform the task(s) it was built to do.\n",
    "\n",
    "One of the best options for working with tabular data in Python is to use the Python Data Analysis Library (a.k.a. Pandas). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading CSV Data Using Pandas "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use Pandas’ read_csv function to pull the file directly into a DataFrame.\n",
    "\n",
    "A DataFrame is a 2-dimensional data structure that can store data of different types (including strings, numbers, categories and more) in columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note that pd.read_csv is used because we imported pandas as pd\n",
    "pd.read_csv(\"data/tmdb-movies.csv\")\n",
    "# The first column is the index of the DataFrame. \n",
    "# The index is used to identify the position of the data, \n",
    "# but it is not an actual column of the DataFrame."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------------------------------------------\n",
    "# SLIDES\n",
    "------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to save the data to memory so we can work with it.\n",
    "To do that, we need to assign the DataFrame to a variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save data to memory\n",
    "my_data = pd.read_csv(\"data/tmdb-movies.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View the data object\n",
    "my_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View the first few lines\n",
    "my_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View object type\n",
    "type(my_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View shape (dimensions)\n",
    "my_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View data types\n",
    "my_data.dtypes\n",
    "# All the values in a single column have the same type.\n",
    "# Some columns cannot contain fractional values\n",
    "# The object type represents strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View info\n",
    "my_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate summary statistics for all numeric columns\n",
    "my_data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are many ways to summarize and access the data stored in DataFrames, using attributes and methods provided by the DataFrame object.\n",
    "\n",
    "Attributes are features of an object.\n",
    "\n",
    "Methods are like functions, but they only work on particular kinds of objects. With a method, we can supply extra information in the parentheses to control behaviour."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------------------------\n",
    "# CHALLENGE 3\n",
    "---------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let’s perform some quick summary statistics to learn more about the data that we’re working with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View columns\n",
    "my_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View unique directors\n",
    "\n",
    "# Option 1\n",
    "pd.unique(my_data['director'])\n",
    "\n",
    "# Option 2\n",
    "director_names = my_data['director']\n",
    "unique_directors = pd.unique(director_names)\n",
    "number_unique_directors = len(unique_directors)\n",
    "print(number_unique_directors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------------------------\n",
    "# CHALLENGE 4\n",
    "---------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------------------------------------------\n",
    "# SLIDES\n",
    "------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Groups in Pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We often want to calculate summary statistics grouped by subsets or attributes within fields of our data.\n",
    "\n",
    "We can calculate basic statistics for all records in a single column using the syntax below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_data['revenue'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also extract one specific metric if we wish:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_data['revenue'].min()\n",
    "my_data['revenue'].max()\n",
    "my_data['revenue'].mean()\n",
    "my_data['revenue'].std()\n",
    "my_data['revenue'].count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But if we want to summarize by one or more variables, we can use Pandas’ `.groupby` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group data by director\n",
    "grouped_data = my_data.groupby('director')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary statistics for all numeric columns by director\n",
    "grouped_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Provide the mean for each numeric column by director\n",
    "grouped_data.mean(numeric_only=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------------------------\n",
    "# CHALLENGE 5\n",
    "---------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let’s next count the number of movies for each year. We’ll use `groupby` combined with a `count()` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_counts = my_data.groupby('release_year')['id'].count()\n",
    "print(movie_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also count just the rows that have the genre \"Thriller\":"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_data.groupby('genres')['release_year'].count()['Thriller']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quick & Easy Plotting Data Using Pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can plot our summary stats using Pandas, too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure figures appear inline in Ipython Notebook\n",
    "%matplotlib inline\n",
    "# Create a quick bar chart\n",
    "movie_counts.plot(kind='bar');\n",
    "# The ; just removes the object type displayed at the top"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------------------------\n",
    "# CHALLENGE 6\n",
    "---------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------------------------------------------\n",
    "# SLIDES\n",
    "------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Indexing and Slicing in Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We often want to work with subsets of a DataFrame object. There are different ways to accomplish this including: using labels (column headings), numeric ranges, or specific x,y index locations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selecting data using Labels (Column Headings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use square brackets [] to select a subset of a Python object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TIP: use the .head() method we saw earlier to make output shorter\n",
    "# Method 1: select a 'subset' of the data using the column name\n",
    "my_data['original_title'].head()\n",
    "\n",
    "# Method 2: use the column name as an 'attribute'; gives the same output\n",
    "my_data.original_title.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also create a new object that contains only the data within the `original_title` column as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creates an object, movie_titles, that only contains the `original_title` column\n",
    "movie_titles = my_data['original_title']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can pass a list of column names too, as an index to select columns in that order. This is useful when we need to reorganize our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the director and release_year columns from the DataFrame\n",
    "my_data[['director', 'release_year']]\n",
    "\n",
    "# What happens when you flip the order?\n",
    "my_data[['release_year', 'director']]\n",
    "\n",
    "# What happens if you ask for a column that doesn't exist?\n",
    "my_data['rating']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracting Range based Subsets: Slicing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Python uses 0-based indexing. This means that the first element in an object is located at position 0. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list of numbers\n",
    "a = [1, 2, 3, 4, 5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Indexing: getting a specific element\n",
    "a[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Slicing: selecting a set of elements\n",
    "a[1:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------------------------\n",
    "# CHALLENGE 7\n",
    "---------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Slicing Subsets of Rows and Columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Slicing using the `[]` operator selects a set of rows and/or columns from a DataFrame. To slice out a set of rows, you use the following syntax: `data[start:stop]`.\n",
    "\n",
    "When slicing in pandas the start bound is included in the output. The stop bound is one step BEYOND the row you want to select. So if you want to select rows 0, 1 and 2 your code would look like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select rows 0, 1, 2 (row 3 is not selected)\n",
    "my_data[0:3]\n",
    "\n",
    "# Select the first 5 rows (rows 0, 1, 2, 3, 4)\n",
    "my_data[:5]\n",
    "\n",
    "# Select the last element in the list\n",
    "# (the slice starts at the last element, and ends at the end of the list)\n",
    "my_data[-1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Copying Objects vs Referencing Objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using the 'copy() method'\n",
    "true_copy_data = my_data.copy()\n",
    "\n",
    "# Using the '=' operator\n",
    "ref_data = my_data\n",
    "\n",
    "# If you change any values in `ref_data`,\n",
    "# it will also change in `my_data`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Subsetting Data using Criteria"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can select specific ranges of our data in both the row and column directions using either label or integer-based indexing.\n",
    "\n",
    "`iloc` is primarily an integer-based indexing counting from 0. That is, you specify rows and columns giving a number. Thus, the first row is row 0, the second column is column 1, etc.\n",
    "\n",
    "`loc` is primarily a label-based indexing where you can refer to rows and columns by their name. E.g., column `year`. Note that integers may be used, but they are interpreted as a label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# iloc[row slicing, column slicing]\n",
    "my_data.iloc[0:3, 1:4]\n",
    "\n",
    "# This yielded 3 rows of data. When you ask for 0:3, \n",
    "# you are actually telling Python to start at index 0 \n",
    "# and select rows 0, 1, 2 up to but not including 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loc[row slicing, column slicing]\n",
    "my_data.loc[0:3, 1:4]\n",
    "# This gives an error, because pandas can't find \n",
    "# columns named \"1\", \"2\", \"3\", or \"4\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When using `loc`, integers can be used, but the integers refer to the index label and not the position. For example, using `loc` and select 1:4 will get a different result than using `iloc` to select rows 1:4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_data.loc[0:3, ['imdb_id', 'popularity', 'budget']]\n",
    "# We have to use LABELS with LOC.\n",
    "# But do you see the difference in the number of rows? \n",
    "# It extract the rows at index 0,1,2 AND 3, because it's using the\n",
    "# index as a LABEL, and not using it as a positional argument.\n",
    "\n",
    "# And remember that the start and stop bounds of loc are included."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select all columns for rows of index values 0 and 10\n",
    "my_data.loc[[0, 10], :]\n",
    "\n",
    "# With loc, both the start bound and the stop bound are inclusive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What does this do?\n",
    "my_data.loc[0, ['release_year', 'director', 'budget']]\n",
    "\n",
    "# Note that labels must be found in the DataFrame or you will get a KeyError."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# What happens when you type the code below?\n",
    "my_data.loc[[0, 10, 3549], :]\n",
    "\n",
    "# With loc, both the start bound and the stop bound are inclusive."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also select a specific data value using a row and column location within the DataFrame and iloc indexing:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Syntax for iloc indexing to finding a specific data element:\n",
    "\n",
    "`data.iloc[row, column]`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Subsetting Data using Criteria"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also select a subset of our data using criteria. Let's select all the movies that were released in 2005."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_data[my_data.release_year == 2005]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or we can select all rows that do not contain the year 2005:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Option 1\n",
    "my_data[my_data != 2005]\n",
    "\n",
    "# Option 2\n",
    "my_data[~(my_data == 2005)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can define sets of criteria too:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_data[(my_data.release_year >= 2000) & (my_data.release_year <= 2005)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------------------------\n",
    "# CHALLENGE 8\n",
    "---------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using masks to identify a specific condition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A mask can be useful to locate where a particular subset of values exist or don’t exist - for example, NaN, or “Not a Number” values. To understand masks, we also need to understand BOOLEAN objects in Python.\n",
    "\n",
    "Boolean values include `True` or `False`. For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set x to 5\n",
    "x = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What does the code below return?\n",
    "x > 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How about this?\n",
    "x == 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Missing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "my_data_missing = pd.read_csv(\"data/tmdb-movies-missing.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let’s try this out. Let’s identify all locations in the data that have null (missing or NaN) data values. We can use the `isnull` method to do this. The `isnull` method will compare each cell with a null value. If an element has a null value, it will be assigned a value of `True` in the output object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.isnull(my_data_missing)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To select the rows where there are null values, we can use the mask as an index to subset our data as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To select just the rows with NaN values, we can use the 'any()' method\n",
    "\n",
    "my_data_missing[pd.isnull(my_data_missing).any(axis=1)]\n",
    "# axis=1 means that it checks across each row."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can run `isnull` on a particular column too. What does the code below do?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What does this do?\n",
    "missing_titles = my_data_missing[pd.isnull(my_data_missing['original_title'])]\n",
    "print(missing_titles)\n",
    "\n",
    "# We are asking Python to select rows that have a NaN value of title, i.e. missing titles.b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's extract the homepages for the movies with missing titles:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_titles['homepage']\n",
    "\n",
    "# You can visit the homepages to get the movie titles."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking the format of our data "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The format of individual columns and rows will impact analysis performed on a dataset read into a pandas DataFrame. For example, you can’t perform mathematical calculations on a string (text formatted data).\n",
    "\n",
    "- Every value has a type.\n",
    "- Use the built-in function type to find the type of a value.\n",
    "- Types control what operations can be done on values.\n",
    "- Strings can be added and multiplied.\n",
    "- Strings have a length (but numbers don’t).\n",
    "- Must convert numbers to strings or vice versa when operating on them.\n",
    "- Can mix integers and floats freely in operations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Types of Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_data['director'].dtype\n",
    "\n",
    "# A type \"O\" stands for \"object\", i.e. string/text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Working With Integers and Floats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we divide one integer by another, we get a float."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(5/9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also convert a floating point number to an integer or an integer to floating point number. Notice that Python by default rounds down when it converts from floating point to integer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert a to an integer\n",
    "a = 7.83\n",
    "int(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert b to a float\n",
    "b = 7\n",
    "float(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Working With Our Movies Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the id field from an integer to a float\n",
    "my_data['id'] = my_data['id'].astype('float64')\n",
    "my_data['id'].dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------------------------\n",
    "# CHALLENGE 9\n",
    "---------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Missing Data Values - NaN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NaN (Not a Number) values are undefined values that cannot be represented mathematically. pandas, for example, will read an empty cell in a CSV or Excel sheet as NaN."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NaNs have some desirable properties: if we were to average the `budget` column without replacing our NaNs, Python would know to skip over those cells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_data_missing['budget'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dealing with missing data values is always a challenge.\n",
    "\n",
    "It’s sometimes hard to know why values are missing:\n",
    "- Was it because of a data entry error?\n",
    "- Or data that someone was unable to collect?\n",
    "- Should the value be 0? \n",
    "\n",
    "We need to know how missing values are represented in the dataset in order to make good decisions. If we’re lucky, we have some metadata that will tell us more about how null values were handled."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can figure out how many rows contain NaN values for `popularity`. We can also create a new subset from our data that only contains rows with popularity > 0 (i.e., select meaningful values):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(my_data_missing[my_data_missing['popularity'].isna()])\n",
    "\n",
    "# How many rows have popularity values?\n",
    "len(my_data_missing[my_data_missing['popularity'] > 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can replace all `NaN` values with zeroes using the .`fillna()` method (after making a copy of the data so we don’t lose our work):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = my_data_missing.copy()\n",
    "# Fill all NaN values with 0\n",
    "df1['popularity'] = df1['popularity'].fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However NaN and 0 yield different analysis results. The mean value when NaN values are replaced with 0 is different from when NaN values are simply thrown out or ignored."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1['popularity'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can fill NaN values with any value that we chose. The code below fills all NaN values with a mean for all popularity values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1['popularity'] = df1['popularity'].fillna(df1['popularity'].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------------------------\n",
    "# CHALLENGE 10\n",
    "---------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Writing Out Data to CSV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let’s reload the data so we’re not mixing up all of our previous manipulations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_data = pd.read_csv(\"data/tmdb-movies.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let’s drop all the rows that contain missing values. We will use the command `dropna`. By default, `dropna` removes rows that contain missing data for even just one column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_na = my_data.dropna()\n",
    "\n",
    "# Note: If you want to drop rows with missing values in a specific column:\n",
    "df_na = my_data.dropna(subset=['popularity'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Export a DataFrame in CSV format and save it in the `data_output` directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write DataFrame to CSV\n",
    "df_na.to_csv('data_output/movies_complete.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------------------------------------------\n",
    "# SLIDES\n",
    "------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Concatenating DataFrames"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We often need to combine data files into a single DataFrame to analyze the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use the `concat` function in pandas to append either columns or rows from one DataFrame to another."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in first 10 lines of table\n",
    "data_sub = my_data.head(10)\n",
    "\n",
    "# Grab the last 10 rows\n",
    "data_sub_last10 = my_data.tail(10)\n",
    "\n",
    "# Reset the index values to the second dataframe appends properly\n",
    "data_sub_last10 = data_sub_last10.reset_index(drop=True)\n",
    "\n",
    "# drop=True option avoids adding new index column with old index values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we concatenate DataFrames, we need to specify the axis:\n",
    "- `axis=0` will stack the second DataFrame UNDER the first one. Columns need to have the same name and data types.\n",
    "- `axis=1` will stack the columns in the second DataFrame to the RIGHT of the first DataFrame. Rows need to be related."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stack the DataFrames on top of each other\n",
    "vertical_stack = pd.concat([data_sub, data_sub_last10], axis=0)\n",
    "vertical_stack\n",
    "\n",
    "# Note that the row indexes for the two dataframes have been repeated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reindex the new DataFrame using the reset_index() method\n",
    "vertical_stack = vertical_stack.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write DataFrame to CSV\n",
    "vertical_stack.to_csv('data_output/out.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Place the DataFrames side by side\n",
    "horizontal_stack = pd.concat([data_sub, data_sub_last10], axis=1)\n",
    "horizontal_stack"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Joining DataFrames"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we concatenated our DataFrames, we simply added them to each other - stacking them either vertically or side by side. Another way to combine DataFrames is to use columns in each dataset that contain common values (a common unique identifier).\n",
    "\n",
    "The columns containing the common values are called “join key(s)”. Joining DataFrames in this way is often useful when one DataFrame is a “lookup table” containing additional data that we want to include in the other."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import multiple data files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Many functions in Python have a set of options that can be set by the user if needed. Let's tell pandas to assign empty values in our CSV to NaN with the parameters `keep_default_na=False` and `na_values=[\"\"]`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies = pd.read_csv(\"data/movies.csv\",\n",
    "                   keep_default_na=False,\n",
    "                   na_values=[\"\"])\n",
    "\n",
    "movies.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings = pd.read_csv(\"data/ratings.csv\",\n",
    "                   keep_default_na=False,\n",
    "                   na_values=[\"\"])\n",
    "\n",
    "ratings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Identifying join keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In our example, the join key is the `movieId` column."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Types of joins\n",
    "\n",
    "#### Inner join\n",
    "- Returns a new DataFrame that contains only those rows that have matching values in both of the original DataFrames.\n",
    "- `merged_inner = pd.merge(left=df1, right=df2, left_on='col1', right_on='col2')`\n",
    "\n",
    "#### Left join\n",
    "- Returns all of the rows from the left DataFrame, even those rows whose join key(s) do not have values in the right DataFrame.\n",
    "- `merged_left = pd.merge(left=df1, right=df2, how='left', left_on='col1', right_on='col2')`\n",
    "\n",
    "#### Right join\n",
    "- Returns all of the rows from the right DataFrame, even those rows whose join key(s) do not have values in the left DataFrame.\n",
    "- `merged_right = pd.merge(left=df1, right=df2, how='right', left_on='col1', right_on='col2')`\n",
    "\n",
    "#### Full (outer) join\n",
    "- Returns all pairwise combinations of rows from both DataFrames.\n",
    "- `merged_outer = pd.merge(left=df1, right=df2, how='outer', left_on='col1', right_on='col2')`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inner join\n",
    "\n",
    "# Option 1\n",
    "merged_inner = pd.merge(left=movies, right=ratings, left_on='movieId', right_on='movieId')\n",
    "\n",
    "# Option 2\n",
    "merged_inner = pd.merge(left=movies, right=ratings, on='movieId')\n",
    "\n",
    "merged_inner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Left join\n",
    "merged_left = pd.merge(left=movies, right=ratings, on='movieId', how='left')\n",
    "merged_left"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Right join\n",
    "merged_right = pd.merge(left=movies, right=ratings, on='movieId', how='right')\n",
    "merged_right"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Full (outer) join\n",
    "merged_outer = pd.merge(left=movies, right=ratings, on='movieId', how='outer')\n",
    "merged_outer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------------------------------------------\n",
    "# SLIDES\n",
    "------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Plotting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create a copy of our `merged_inner` data and make some plots with that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_complete = merged_inner.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot data directly from a Pandas dataframe\n",
    "data_complete['rating'].plot(kind='hist')\n",
    "plt.title('Distribution of Movie Ratings')\n",
    "plt.xlabel('Rating')\n",
    "plt.ylabel('Frequency')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.hist(data_complete['rating'], bins=5, color='skyblue', edgecolor='black')\n",
    "plt.title('Distribution of Movie Ratings')\n",
    "plt.xlabel('Rating')\n",
    "plt.ylabel('Frequency')\n",
    "\n",
    "# Save the plot before showing it\n",
    "plt.savefig('fig_output/matplotlib_histogram.png', dpi=300, bbox_inches='tight')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Seaborn\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.histplot(data_complete['rating'], bins=5, color='skyblue', kde=False)\n",
    "plt.title('Distribution of Movie Ratings')\n",
    "plt.xlabel('Rating')\n",
    "plt.ylabel('Frequency')\n",
    "\n",
    "# Save the plot before showing it\n",
    "plt.savefig('fig_output/seaborn_histogram.png', dpi=300, bbox_inches='tight')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Plotnine\n",
    "from plotnine import ggplot, aes, geom_histogram, ggtitle, labs, theme_classic\n",
    "\n",
    "plot = (ggplot(data_complete, aes(x='rating')) +\n",
    "        geom_histogram(bins=5, fill='skyblue', color='black') +\n",
    "        ggtitle('Distribution of Movie Ratings') +\n",
    "        labs(x='Rating', y='Frequency') +\n",
    "        theme_classic())\n",
    "        \n",
    "print(plot)\n",
    "\n",
    "# Save the plot\n",
    "plot.save('fig_output/plotnine_histogram.png', dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These examples provide the same output visually but differ significantly in the way they are coded. The choice between them depends on the user's preference for customization, simplicity, and familiarity with the plotting paradigm.\n",
    "\n",
    "#### Summary of Differences\n",
    "\n",
    "**Matplotlib:**\n",
    "\n",
    "- Requires more boilerplate code (e.g., `plt.figure()`, `plt.show()`).\n",
    "- Customisation (color, labels) is done through method arguments.\n",
    "- The histogram is created using `plt.hist()`.\n",
    "\n",
    "**Seaborn:**\n",
    "\n",
    "- Less code than Matplotlib, with some additional aesthetics by default.\n",
    "- Histogram created with `sns.histplot()`; `kde=False` disables the kernel density estimate line.\n",
    "- Integrates with Matplotlib for underlying plotting but adds simplicity.\n",
    "\n",
    "**Plotnine:**\n",
    "\n",
    "- Follows a declarative style with the *Grammar of Graphics* approach.\n",
    "- Plots are constructed by layering components (`ggplot`, `aes`, `geom_histogram`).\n",
    "- Requires fewer explicit function calls for titles and labels but uses a more complex syntax."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------------------------------------------\n",
    "# SLIDES\n",
    "------------------------------------------------------"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
