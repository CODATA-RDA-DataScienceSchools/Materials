{"config":{"lang":["en"],"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"CODATA/RDA Schools for Research Data Science Materials from DataKigali 2018 Materials from DataSaoPaulo 2018 Materials from DataTrieste 2019 Materials from DataSanJose 2019","title":"Home"},{"location":"#codatarda-schools-for-research-data-science","text":"Materials from DataKigali 2018 Materials from DataSaoPaulo 2018 Materials from DataTrieste 2019 Materials from DataSanJose 2019","title":"CODATA/RDA Schools for Research Data Science"},{"location":"DataKigali2018/","text":"Kigali Foundational School in Research Data Science 22 October \u2013 2 November, 2018 University of Rwanda, Kigali, Rwanda Background and purpose The goal of this workshop is to train researchers in Research Data Science (RDS). RDS refers to the principles and practice of Open Science and research data management and curation, the use of a range of data platforms and infrastructures, large scale analysis, statistics, visualization and modelling techniques, software development and data annotation. These are important tools for extracting useful information from data and these tools are useful in every research area. A 10-day workshop, organized by CODATA, RDA, ICTP and EAIFR, was conducted at the University of Rwanda, Kigali to introduce participants to the skills of RDS. Materials for the 2018 School of Research Data Science in Kigali Day 1 - Introduction, Open Science , UNIX Shell Day 2 - Version Control with Git , Introduction to R Day 3 - Introduction to R Day 4 - Research Data Management Day 5 - Research Data Management , Open Science Day 6 - Data Visualization Day 7 - Overview of Machine Learning - 20of 20Machine 20Learning 202018.pdf\">Fundamentals , 20Systems 202018.pdf\">Recommender Systems Day 8 - Artificial Neural Networks Day 9 - Computational Infrastructures - Lecture 1 , Lecture 2 , Lecture 3 , Day 10 - Computational Infrastructures Wrap-Up - Lecture 4 , School Close Out","title":"Kigali Foundational School in Research Data Science"},{"location":"DataKigali2018/#kigali-foundational-school-in-research-data-science","text":"22 October \u2013 2 November, 2018 University of Rwanda, Kigali, Rwanda","title":"Kigali Foundational School in Research Data Science"},{"location":"DataKigali2018/#background-and-purpose","text":"The goal of this workshop is to train researchers in Research Data Science (RDS). RDS refers to the principles and practice of Open Science and research data management and curation, the use of a range of data platforms and infrastructures, large scale analysis, statistics, visualization and modelling techniques, software development and data annotation. These are important tools for extracting useful information from data and these tools are useful in every research area. A 10-day workshop, organized by CODATA, RDA, ICTP and EAIFR, was conducted at the University of Rwanda, Kigali to introduce participants to the skills of RDS.","title":"Background and purpose"},{"location":"DataKigali2018/#materials-for-the-2018-school-of-research-data-science-in-kigali","text":"Day 1 - Introduction, Open Science , UNIX Shell Day 2 - Version Control with Git , Introduction to R Day 3 - Introduction to R Day 4 - Research Data Management Day 5 - Research Data Management , Open Science Day 6 - Data Visualization Day 7 - Overview of Machine Learning - 20of 20Machine 20Learning 202018.pdf\">Fundamentals , 20Systems 202018.pdf\">Recommender Systems Day 8 - Artificial Neural Networks Day 9 - Computational Infrastructures - Lecture 1 , Lecture 2 , Lecture 3 , Day 10 - Computational Infrastructures Wrap-Up - Lecture 4 , School Close Out","title":"Materials for the 2018 School of Research Data Science in Kigali"},{"location":"DataKigali2018/slides/readme/","text":"Slides folder","title":"Readme"},{"location":"DataKigali2018/slides/DataVizMaterials/readme/","text":"download the folder for data visualization materials","title":"Readme"},{"location":"DataSanJose2019/","text":"San Jos\u00e9 School of Research Data Science December 2 \u2013 13, 2018 CeNAT, San Jos\u00e9, Costa Rica Background and purpose The goal of this workshop is to train researchers in Research Data Science (RDS). RDS refers to the principles and practice of Open Science and research data management and curation, the use of a range of data platforms and infrastructures, large scale analysis, statistics, visualization and modelling techniques, software development and data annotation. These are important tools for extracting useful information from data and these tools are useful in every research area. A 10-day workshop, organized by CODATA, RDA, CONARE and CeNAT, was conducted at the CeNAT, San Jos\u00e9 to introduce participants to the skills of RDS. Materials for the 2019 School of Research Data Science in San Jos\u00e9 Day 1 - Introduction , Open Science , UNIX Shell Day 2 - Version Control with Git , Introduction to Python Day 3 - Introduction to Python Day 4 - Author Carpentry , Intro to Research Data Management Day 5 - Research Data Management , Data Management Plans Day 6 - 20using 20Seaborn.md\">Data Visualization Day 6 - Open Science , Information Security Day 7 - Overview of Machine Learning Day 8 - Artificial Neural Networks Day 9 - Computational Infrastructures - Lecture 1 , Lecture 2 , Lecture 3 , Lecture 4 Day 10 - Computational Infrastructures Wrap-Up - Lecture 5 , Lecture 6 School Close Out","title":"San Jos\u00e9 School of Research Data Science"},{"location":"DataSanJose2019/#san-jose-school-of-research-data-science","text":"December 2 \u2013 13, 2018 CeNAT, San Jos\u00e9, Costa Rica","title":"San Jos\u00e9 School of Research Data Science"},{"location":"DataSanJose2019/#background-and-purpose","text":"The goal of this workshop is to train researchers in Research Data Science (RDS). RDS refers to the principles and practice of Open Science and research data management and curation, the use of a range of data platforms and infrastructures, large scale analysis, statistics, visualization and modelling techniques, software development and data annotation. These are important tools for extracting useful information from data and these tools are useful in every research area. A 10-day workshop, organized by CODATA, RDA, CONARE and CeNAT, was conducted at the CeNAT, San Jos\u00e9 to introduce participants to the skills of RDS.","title":"Background and purpose"},{"location":"DataSanJose2019/#materials-for-the-2019-school-of-research-data-science-in-san-jose","text":"Day 1 - Introduction , Open Science , UNIX Shell Day 2 - Version Control with Git , Introduction to Python Day 3 - Introduction to Python Day 4 - Author Carpentry , Intro to Research Data Management Day 5 - Research Data Management , Data Management Plans Day 6 - 20using 20Seaborn.md\">Data Visualization Day 6 - Open Science , Information Security Day 7 - Overview of Machine Learning Day 8 - Artificial Neural Networks Day 9 - Computational Infrastructures - Lecture 1 , Lecture 2 , Lecture 3 , Lecture 4 Day 10 - Computational Infrastructures Wrap-Up - Lecture 5 , Lecture 6 School Close Out","title":"Materials for the 2019 School of Research Data Science in San Jos\u00e9"},{"location":"DataSanJose2019/CI/00-Pre-Introduction-Login/","text":"Install an SSH-Cleint Download and install a SSH Client. We recommend PuTTY, but any ssh client is acceptable. https://www.putty.org/ Direct link to executable After opening the executable you should see the following screen: Authentication for CI Exercises You will receive login credentials at the beginning of this session. To authenticate (prove you who you say you are and establish what you are authorized to do) the bridgekeeper (login nodes) requires three bits of information: From Monty Python and the Holy Grail: BRIDGEKEEPER: Hee hee heh. Stop! What... is your name?\\ ARTHUR: It is 'Arthur', King of the Britons.\\ BRIDGEKEEPER: What... is your quest?\\ ARTHUR: To seek the Holy Grail.\\ BRIDGEKEEPER: What... is the air-speed velocity of an unladen swallow?\\ ARTHUR: What do you mean? An African or European swallow?\\ BRIDGEKEEPER: Huh? I-- I don't know that. Auuuuuuuugh!\\ BEDEVERE: How do know so much about swallows?\\ ARTHUR: Well, you have to know these things when you're a king, you know. or... 1) Tell me who you are. 2) Tell me something only you know. 3) Show me someething only you have. Why do you need both a password and a key? What is the role of the password in the public-private key scheme? Where you will work You will be logging into training.osgconnect.net for the CyberInfrastructure exercises. To confirm you have the proper authentication and authorization to do the exercises tomorrow and Friday we will test logins today. Due to the local network firewall setup (another security mechanism) and key installation, we will go to Brazil first (thanks to Raphael for setting up temporary VM). First be sure you are on the wireless network Eventos CeNAT . Replace XX with your osguser ID and use the password you have been supplied with the following command. ssh -o PreferredAuthentications=password osguserXX@200.145.46.31 If you are using putty, you should fill the Host Name (or IP address) with the value 200.145.46.31 as seen below: After hitting the Open button you may see the following message: You should hit the Yes button. Login on our submission node using the following command along with the password you have been supplied. $ ssh training.osgconnect.net The authenticity of host 'training.osgconnect.net (128.135.158.220)' can't be established. ECDSA key fingerprint is SHA256:gielJSpIiZisxGna5ocHtiK+0zAqFTdcEkLBOgnDUsg. Are you sure you want to continue connecting (yes/no)? yes Warning: Permanently added 'training.osgconnect.net,128.135.158.220' (ECDSA) to the list of known hosts. Enter passphrase for key '/home/osguser01/.ssh/id_rsa': You may get a message asking you to establish the authenticity of this connection. Answer \"yes\". When you login to the machine you will be in your \"home directory\". We recommend that you work in this directory as nobody else can modify the files here (what security concept we covered today does this recommendation satisfy?).","title":"00 Pre Introduction Login"},{"location":"DataSanJose2019/CI/00-Pre-Introduction-Login/#install-an-ssh-cleint","text":"Download and install a SSH Client. We recommend PuTTY, but any ssh client is acceptable. https://www.putty.org/ Direct link to executable After opening the executable you should see the following screen:","title":"Install an SSH-Cleint"},{"location":"DataSanJose2019/CI/00-Pre-Introduction-Login/#authentication-for-ci-exercises","text":"You will receive login credentials at the beginning of this session. To authenticate (prove you who you say you are and establish what you are authorized to do) the bridgekeeper (login nodes) requires three bits of information: From Monty Python and the Holy Grail: BRIDGEKEEPER: Hee hee heh. Stop! What... is your name?\\ ARTHUR: It is 'Arthur', King of the Britons.\\ BRIDGEKEEPER: What... is your quest?\\ ARTHUR: To seek the Holy Grail.\\ BRIDGEKEEPER: What... is the air-speed velocity of an unladen swallow?\\ ARTHUR: What do you mean? An African or European swallow?\\ BRIDGEKEEPER: Huh? I-- I don't know that. Auuuuuuuugh!\\ BEDEVERE: How do know so much about swallows?\\ ARTHUR: Well, you have to know these things when you're a king, you know. or... 1) Tell me who you are. 2) Tell me something only you know. 3) Show me someething only you have. Why do you need both a password and a key? What is the role of the password in the public-private key scheme?","title":"Authentication for CI Exercises"},{"location":"DataSanJose2019/CI/00-Pre-Introduction-Login/#where-you-will-work","text":"You will be logging into training.osgconnect.net for the CyberInfrastructure exercises. To confirm you have the proper authentication and authorization to do the exercises tomorrow and Friday we will test logins today. Due to the local network firewall setup (another security mechanism) and key installation, we will go to Brazil first (thanks to Raphael for setting up temporary VM). First be sure you are on the wireless network Eventos CeNAT . Replace XX with your osguser ID and use the password you have been supplied with the following command. ssh -o PreferredAuthentications=password osguserXX@200.145.46.31 If you are using putty, you should fill the Host Name (or IP address) with the value 200.145.46.31 as seen below: After hitting the Open button you may see the following message: You should hit the Yes button. Login on our submission node using the following command along with the password you have been supplied. $ ssh training.osgconnect.net The authenticity of host 'training.osgconnect.net (128.135.158.220)' can't be established. ECDSA key fingerprint is SHA256:gielJSpIiZisxGna5ocHtiK+0zAqFTdcEkLBOgnDUsg. Are you sure you want to continue connecting (yes/no)? yes Warning: Permanently added 'training.osgconnect.net,128.135.158.220' (ECDSA) to the list of known hosts. Enter passphrase for key '/home/osguser01/.ssh/id_rsa': You may get a message asking you to establish the authenticity of this connection. Answer \"yes\". When you login to the machine you will be in your \"home directory\". We recommend that you work in this directory as nobody else can modify the files here (what security concept we covered today does this recommendation satisfy?).","title":"Where you will work"},{"location":"DataSanJose2019/CI/01-Introduction/","text":"High Throughput Computing and Condor Introduction Preliminaries You will receive login credentials at the beginning of this session. You might want to refer to the online Condor 8.6.13 manual . You may enjoy browsing the Condor web page . Which Condor? We will be using Condor 8.6.13, which is a recent production version of Condor. Condor has two coexisting types of releases at any given time: stable and development. Condor 8.2.X and 7.8.x are considered stable releases, and you can know they are stable because the second digits (a 2 or a 8 in these cases) are even numbers. In a given stable series, all versions have the same features (for example 7.8.0 and 7.8.1 have the same set of features) and differ only in bug fixes. Where you will work Today you will log into training.osgconnect.net for all of your exercises. Login on submission node using the directions from yesterdays security session. They can be found here . When you login to the machine you will be in your \"home directory\". We recommend that you work in this directory as nobody else can modify the files here. You can always return to your home directory by running the command $ cd ~ The Exercises Throughout the Condor exercises, you will be given a fair amount of guidance. In several spots, there are suggestions for extra exercises to do \"on your own\" or as \"challenges\". Since you aren't being graded, there is no extra credit for doing them, but we encourage you to try them out. If you prefer, you can come back to the extra credit after you've completed the basic exercises. If you simply cruise through the exercises, you'll probably have free time--we encourage you to delve in more deeply. For all of the exercises, we'll assume that you are logged into user-training.osgconnect.net. You should have received your name and password for user-training.osgconnect.net at the beginning of the Computation Infrastructures lecture.","title":"High Throughput Computing and Condor Introduction"},{"location":"DataSanJose2019/CI/01-Introduction/#high-throughput-computing-and-condor-introduction","text":"","title":"High Throughput Computing and Condor Introduction"},{"location":"DataSanJose2019/CI/01-Introduction/#preliminaries","text":"You will receive login credentials at the beginning of this session. You might want to refer to the online Condor 8.6.13 manual . You may enjoy browsing the Condor web page .","title":"Preliminaries"},{"location":"DataSanJose2019/CI/01-Introduction/#which-condor","text":"We will be using Condor 8.6.13, which is a recent production version of Condor. Condor has two coexisting types of releases at any given time: stable and development. Condor 8.2.X and 7.8.x are considered stable releases, and you can know they are stable because the second digits (a 2 or a 8 in these cases) are even numbers. In a given stable series, all versions have the same features (for example 7.8.0 and 7.8.1 have the same set of features) and differ only in bug fixes.","title":"Which Condor?"},{"location":"DataSanJose2019/CI/01-Introduction/#where-you-will-work","text":"Today you will log into training.osgconnect.net for all of your exercises. Login on submission node using the directions from yesterdays security session. They can be found here . When you login to the machine you will be in your \"home directory\". We recommend that you work in this directory as nobody else can modify the files here. You can always return to your home directory by running the command $ cd ~","title":"Where you will work"},{"location":"DataSanJose2019/CI/01-Introduction/#the-exercises","text":"Throughout the Condor exercises, you will be given a fair amount of guidance. In several spots, there are suggestions for extra exercises to do \"on your own\" or as \"challenges\". Since you aren't being graded, there is no extra credit for doing them, but we encourage you to try them out. If you prefer, you can come back to the extra credit after you've completed the basic exercises. If you simply cruise through the exercises, you'll probably have free time--we encourage you to delve in more deeply. For all of the exercises, we'll assume that you are logged into user-training.osgconnect.net. You should have received your name and password for user-training.osgconnect.net at the beginning of the Computation Infrastructures lecture.","title":"The Exercises"},{"location":"DataSanJose2019/slides/Visualisation/Visualisation using Seaborn/","text":"Visualisation using Seaborn The notes listed here are based on this DataCamp tutorial on Seaborn by Karlijn Willems and this CODATA-RDA module on visualisation by Sara El Jadid . During this module we'll be making use of Seaborn , which provides a high-level interface to draw statistical graphics. Seaborn vs Matplotlib Seaborn is complimentary to Matplotlib and it specifically targets statistical data visualization. But it goes even further than that: Seaborn extends Matplotlib and that\u2019s why it can address the two biggest frustrations of working with Matplotlib. Or, as Michael Waskom says in the \u201c introduction to Seaborn \u201d: \u201cIf matplotlib \u201ctries to make easy things easy and hard things possible\u201d, seaborn tries to make a well-defined set of hard things easy too.\u201d One of these hard things or frustrations had to do with the default Matplotlib parameters. Seaborn works with different parameters, which undoubtedly speaks to those users that don\u2019t use the default looks of the Matplotlib plots. During this module we'll also be making some use of Pandas to extract features of the data that we need. Getting started In the first instance please get yourself set up with a notebook on the Google colab site. Please go to https://colab.research.google.com/notebooks/welcome.ipynb and then click on File and New Python 3 notebook. OR log into the Kabre jupyter server and then click on New and then New Python 3. We'll start with importing a set of libraries that will be useful for us and the gapminder data set. import numpy as np import pandas as pd import matplotlib.pyplot as plt import seaborn as sns sns.set(style=\"darkgrid\") The last line is a choice about how things look - you may want to leave that out. Now we'll read in the data. We will again use the gapminder data set but with the columns labelled differently. Please do not use the version you have used previously. The version is stored on a github repository which has been shortened using bit.ly. url=\"http://bit.ly/2PbVBcR\" #url=\"https://raw.githubusercontent.com/CODATA-RDA-DataScienceSchools/Materials/master/docs/DataSanJose2019/slides/Visualisation/gapminder.csv\" gapminder=pd.read_csv(url) So we are using pandas to read in the data set. The gapminder data set is a Data Frame . Exploring the gapminder data set The gapminder data set is a set of socioeconomic data about populations, GDP per capita and expected life span for a large number of countries over a number of years. We can have a look at it using the head command. gapminder.head() You should get something like this. Unnamed: 0 country continent year lifeExp pop gdpPercap 0 1 Afghanistan Asia 1952 28.801 8425333 779.445314 1 2 Afghanistan Asia 1957 30.332 9240934 820.853030 2 3 Afghanistan Asia 1962 31.997 10267083 853.100710 3 4 Afghanistan Asia 1967 34.020 11537966 836.197138 4 5 Afghanistan Asia 1972 36.088 13079460 739.981106 So it is a combination of categorical data (countries and continents) and quantitative data (year, lifeExp etc.). It's also nice (though unrealistic) that it doesn't have missing values or malformed data e.g. Ireland is written sometimes as \"Ireland\" and sometimes \"ireland\" and sometimes \"Republic of Ireland\" or even \"Eire\"!! Dealing with those kinds of issues is not what we're going to focus on here. We can do a statistical summary of the numerical data using the describe function gapminder.describe() Unnamed: 0 year lifeExp pop gdpPercap count 1704.000000 1704.00000 1704.000000 1.704000e+03 1704.000000 mean 852.500000 1979.50000 59.474439 2.960121e+07 7215.327081 std 492.046746 17.26533 12.917107 1.061579e+08 9857.454543 min 1.000000 1952.00000 23.599000 6.001100e+04 241.165877 25% 426.750000 1965.75000 48.198000 2.793664e+06 1202.060309 50% 852.500000 1979.50000 60.712500 7.023596e+06 3531.846989 75% 1278.250000 1993.25000 70.845500 1.958522e+07 9325.462346 max 1704.000000 2007.00000 82.603000 1.318683e+09 113523.132900 One can find the names of the continents by executing the following. list(set(gapminder.continent)) We note that gapminder.continent gives us the list with the column corresponding to the continent entry. The set command converts the list into a set (which only has unique entries) and then list turns that back into a list again. We can list these entries alphabetically from the command sorted(list(set(gapminder.continent))) Exercise What does the function sorted do? Do the same for the countries. The gsapminder data set also presents lots of questions such as Is there a relationship between gdpPercap (roughly a measure of the average wealth of each person in a country) and their average life span? Is the average life span changing over time? How does picture change over different countries or comntinents? Visualisation allows us to explore all of this! Getting started with seaborn Let us start with doing box plots which count the number of entries that we have for each continent. sns.countplot(x=\"continent\", data=gapminder) You should get the folllowing. Note that generically seaborn generally looks like this. sns. (x= , y= , ... , data =< a data frame>) We use countplot here to just count entries and plot them as a box plot. Exercise What happens if we do the following? sns.countplot(x=\"Continent\", data=gapminder) What does that tell us? Printing out You can save a figure as a PNG or as a PDF then in the same cell as the command you run to plot use the savefig command. sns.countplot(x=\"continent\", data=gapminder) plt.savefig(\"Histogram.png\") plt.savefig(\"Histogram.pdf\") Looking at 1-d distributions We can use the command catplot to just look at the distribution of life expenctancies. sns.catplot(y=\"lifeExp\", data=gapminder) You should get something like this. The points are jittered i.e. randomly moved in the horizontal axis to make things clearer. We can switch that off if we wish. sns.catplot(y=\"lifeExp\", data=gapminder,jitter=False) This scatterplot is not very informative! We can create a box plot of the data sns.boxplot(y=\"lifeExp\", data=gapminder) This should give the following. Exercise One can use another type of plot called a violin plot which tries to summarise the distribution better than a boxplot. The width of the violin plot represents how big the distribution is at that value. It is quite useful for picking out multi-modal (one with a distribution that has more than one peak). The command in seaborn is violinplot. Try and implement this for this data. Diving deeper into the data Just looking at the life expectancy for all of the countries isn't very informative. The first thing we can do is ask how does this vary across continents. Seaborn does this easily by introducing an x-axis which is the continent. Again, let's try with just the points. sns.catplot(x=\"continent\", y=\"lifeExp\", data=gapminder) Exercise Repeat this using box plots (and violin plots if you wish). Repeat the above steps using GDP per capita (gdpPercap) instead of life expectancy. You can also try the swarmplot function as another way to represent this data. Can we just draw a distribution or a histogram? What about dividing it as continents? Yes! But we'll get to that in a bit. Ordering Plotting the box plots with the continents in alphabetical order is quite easy. orderedContinents = sorted(list(set(gapminder.continent))) orderedContinents orderedContinents is a list with the continents ordered. sns.boxplot(x=\"continent\", y=\"lifeExp\", order=orderedContinents, data=gapminder) On the other hand we may want to order the box plots in ascending order of the medians of the life expectancy. This is more involved but is a good exercise in manipulating the data. #Create an empty dictionary medianLifeExps = {} # Loop through all the continents for val in gapminder.continent: # Create a new key which is the median life expectancy of that continent # gapminder[gapminder.continent == val] pulls out the continent in that loop # the .lifeExp.median() part then computes the median # of the remaining life expectancy data key = gapminder[gapminder.continent==val].lifeExp.median() # create a new entry in the dictionary with the continent as the value and the key # as the median. medianLifeExps[key] = val # Create a sorted list of the medians (in ascending order) sortedKeys = sorted(medianLifeExps) # Finally return the list of continents in that order orderedMedianContinents = [] for m in orderedMedians: orderedMedianContinents.append(medianLifeExps[m]) sns.boxplot(x=\"continent\", y=\"lifeExp\", order=orderedMedianContinents, data=gapminder) Exercise Do the same plot for GDP per capita. Line and scatter plots Instead of having a categorical variable on the horizontal access we now do scatter and line plots. Let's start with the whole data set. sns.scatterplot(x=\"gdpPercap\",y=\"lifeExp\",data=gapminder) This is hard to grasp as a whole, so we'll just consider one country - China. We can select data corresponding to China by the following. gapminder[gapminder.country==\"China\"] sns.scatterplot(x=\"gdpPercap\",y=\"lifeExp\",data= gapminder[gapminder.country==\"China\"]) Exercise Do the same for your country - if it isn't listed in gapminder then pick another. A line plot works in the same way. It's possible to overlay these in the same cell. sns.lineplot(x=\"gdpPercap\",y=\"lifeExp\",data= gapminder[gapminder.country==\"China\"]) sns.scatterplot(x=\"gdpPercap\",y=\"lifeExp\",data= gapminder[gapminder.country==\"China\"]) Expressing more variables with different attributes It is hard to make out the points from the lines. We can change the colour (color) of the points accordingly. sns.lineplot(x=\"gdpPercap\",y=\"lifeExp\",data= gapminder[gapminder.country==\"China\"]) sns.scatterplot(x=\"gdpPercap\",y=\"lifeExp\",color=\"red\",data= gapminder[gapminder.country==\"China\"]) We can use the colour of the points to represent a different column - e.g. the year. sns.lineplot(x=\"gdpPercap\",y=\"lifeExp\",data= gapminder[gapminder.country==\"China\"]) sns.scatterplot(x=\"gdpPercap\",y=\"lifeExp\",hue=\"year\", data= gapminder[gapminder.country==\"China\"]) The problem here is that only a certain number of years have been picked out. We need to tell seaborn how many years there are and how to set a palette of colours for this (the default palette has six colours). # Find the number of years (why only set?) n = len(set(gapminder.year)) sns.lineplot(x=\"gdpPercap\",y=\"lifeExp\",data= gapminder[gapminder.country==\"China\"]) # We use a rainbow-like palette but there are others. sns.scatterplot(x=\"gdpPercap\",y=\"lifeExp\",hue=\"year\",palette=sns.color_palette(\"rainbow_r\",n), data= gapminder[gapminder.country==\"China\"]) We can use the size of the point to represent an additional column - the population. n = len(set(gapminder.year)) sns.lineplot(x=\"gdpPercap\",y=\"lifeExp\",data= gapminder[gapminder.country==\"China\"]) sns.scatterplot(x=\"gdpPercap\",y=\"lifeExp\",hue=\"year\",size=\"pop\", palette=sns.color_palette(\"rainbow_r\",n), data= gapminder[gapminder.country==\"China\"]) The problem now is that there is too much detail in the legend - so we'll switch that off. n = len(set(gapminder.year)) sns.lineplot(x=\"gdpPercap\",y=\"lifeExp\",data= gapminder[gapminder.country==\"China\"]) sns.scatterplot(x=\"gdpPercap\",y=\"lifeExp\",hue=\"year\",size=\"pop\", palette=sns.color_palette(\"rainbow_r\",n), data= gapminder[gapminder.country==\"China\"], legend=False) How useful is adding these attributes? Exercise Pick another country and try this out. Costa Rica is interesting. Does anybody have an explanation? Summarising We will now examine how life expenctancy has varied over time. sns.lineplot(x=\"year\",y=\"lifeExp\",hue=\"country\",data= gapminder,legend=False) There are so many countries here I haven't even tried to construct a palette! Looking at this many countries are generally increasing but some are not following that trend. We could explore those outliers but here we will focus on trying to summarise what is going on (is a particular continent not going with the trend of increasing life span over time?) To do this we need to use another pandas command groupby which creates a new data frame for particular variables. Once we have created that new data frame we can then plot the data. # First create a new data frame which has the medians, by year and continent, of the life expectancy medianGapminder = gapminder.groupby(['continent','year']).lifeExp.median() # Now plot it sns.lineplot(x=\"year\",y=\"lifeExp\",hue=\"continent\",data= medianGapminder) What happened? The groupby command makes continent and year indices of the data (you can see this if you print out the data frame). Having created the data frame we need to reset the indices. # First create a new data frame which has the medians, by year and continent, of the life expectancy medianGapminder = gapminder.groupby(['continent','year']).lifeExp.median() # Now plot it sns.lineplot(x=\"year\",y=\"lifeExp\",hue=\"continent\",data= medianGapminder.reset_index()) Exercise Repeat this using the GDP per capita. Use a different statistical summary apart from the median. Regression The line plots just \"join the dots\". It is more intesting to try and fit the data to a curve. We also want to do the fit and distinguish between the different continents. We can do this using the lmplot command. sns.lmplot(x=\"year\",y=\"lifeExp\",hue=\"continent\", data= medianGapminder.reset_index()) This does a simple linear regression. We can do more sophisticated types of fit, for example Loess (or Lowess). sns.lmplot(x=\"year\",y=\"lifeExp\",hue=\"continent\", lowess=True, data= medianGapminder.reset_index()) Exercise Repeat the above using the GDP per capita. More regression Now that we know how to fit curves through data with a number of different variables we can go back to the case of where we plotted the life expectancy against the GDP per capita. Instead of just doing a scatter plot we can now do regression (curve fitting) as function of the continent as well so we can see how the life expectancy varies between GDP per capita and the continent. sns.lmplot(x=\"gdpPercap\",y=\"lifeExp\",hue=\"continent\", lowess=True,data=gapminder) The problem here is that points are too large - we cannot see the trend. When you have many points make the point size smaller, indeed way smaller (someone described it as 'dust size') to see the trend better. Since Seaborn is based on Matplotlib we need to use a slightly different notation in the arguments to what was used previously. # scatter_kws is passed onto the underlying matplotlib plotting routine. sns.lmplot(x=\"gdpPercap\",y=\"lifeExp\",hue=\"continent\", lowess=True,data=gapminder,scatter_kws={\"s\":5}) The GDP per capita varies over a wide range and it would be good in the first instance to plot the x-axis on a logarithmic scale. Again since Seaborn is based on Matplotlib we need to use a slightly different notation to what was used previously. ax = sns.lmplot(x=\"gdpPercap\",y=\"lifeExp\",hue=\"continent\", lowess=True, data=gapminder,scatter_kws={\"s\":5}) ax.set(xscale=\"log\") We now get a much better spread of the data but it's still hard to see how the different continents are behaving. To do that we make use of facet plots . These are simply plots of different but related variables that are organised on the same screen for easy comparison. ax = sns.lmplot(x=\"gdpPercap\",y=\"lifeExp\",col=\"continent\", lowess=True, data=gapminder,scatter_kws={\"s\":5}) ax.set(xlim=(100,200000),xscale=\"log\") We note that the axes of all of these plots are the same so we can do a valid comparison. Still these plots are quite squashed as thy try and fit to the width of the page. Instead we can wrap them around. ax = sns.lmplot(x=\"gdpPercap\",y=\"lifeExp\",col=\"continent\", col_wrap=2, lowess=True, data=gapminder,scatter_kws={\"s\":5}) ax.set(xlim=(100,200000),xscale=\"log\") Finally, we can adjust the colour of the individual plots. ax = sns.lmplot(x=\"gdpPercap\",y=\"lifeExp\",col=\"continent\", hue=\"continent\", col_wrap=2, lowess=True, data=gapminder,scatter_kws={\"s\":5}) ax.set(xlim=(100,200000),xscale=\"log\") Exercise Do the same type of plots for life expectancy against year. Distributions We can plot the distribution of a list of data (one column from a data frame) using a kernal density approach and/or a histogram. sns.distplot(gapminder.lifeExp) distplot only allows a single column from a data frame! You can also add the raw data into this plot as well (although this isn't very useful in this case as there's so much data). sns.distplot(gapminder.lifeExp,rug=True) Exercise Do the same type of plot with the GDP per capita data. Again we would like to break this down in separate continents. Again we will make use of facet plots. lmplot is designed to create facet plots but distplot isn't so we need to use a specific function called FacetGrid to do this. In the call below we also adjust the height and aspect (the height/width ratio) of the figures. # Create a facet of the gapminder data based on the continents ordered alphabetically (orderedContinents) g = sns.FacetGrid(gapminder, row=\"continent\", row_order=orderedContinents, height=2, aspect=4) # Plot on the facets the distribution of the life expctancy data, but don't plot the histogram. g.map(sns.distplot, \"lifeExp\", hist=False) Finally the facet plot can also be used with just one facet! # Create a facet plot with one facet but colour on continent. g = sns.FacetGrid(gapminder, hue=\"continent\",height=2, aspect=4) # Plot the distributions with no histogram g.map(sns.distplot, \"lifeExp\", hist=False) # Give the colour scheme in a legend g.add_legend() Exercise Do the same type of plot with the GDP per capita data (Longer) Select the data from the gapminder data set for a particular continent and now create facet plots for those countries.","title":"Visualisation using Seaborn"},{"location":"DataSanJose2019/slides/Visualisation/Visualisation using Seaborn/#visualisation-using-seaborn","text":"The notes listed here are based on this DataCamp tutorial on Seaborn by Karlijn Willems and this CODATA-RDA module on visualisation by Sara El Jadid . During this module we'll be making use of Seaborn , which provides a high-level interface to draw statistical graphics.","title":"Visualisation using Seaborn"},{"location":"DataSanJose2019/slides/Visualisation/Visualisation using Seaborn/#seaborn-vs-matplotlib","text":"Seaborn is complimentary to Matplotlib and it specifically targets statistical data visualization. But it goes even further than that: Seaborn extends Matplotlib and that\u2019s why it can address the two biggest frustrations of working with Matplotlib. Or, as Michael Waskom says in the \u201c introduction to Seaborn \u201d: \u201cIf matplotlib \u201ctries to make easy things easy and hard things possible\u201d, seaborn tries to make a well-defined set of hard things easy too.\u201d One of these hard things or frustrations had to do with the default Matplotlib parameters. Seaborn works with different parameters, which undoubtedly speaks to those users that don\u2019t use the default looks of the Matplotlib plots. During this module we'll also be making some use of Pandas to extract features of the data that we need.","title":"Seaborn vs Matplotlib"},{"location":"DataSanJose2019/slides/Visualisation/Visualisation using Seaborn/#getting-started","text":"In the first instance please get yourself set up with a notebook on the Google colab site. Please go to https://colab.research.google.com/notebooks/welcome.ipynb and then click on File and New Python 3 notebook.","title":"Getting started"},{"location":"DataSanJose2019/slides/Visualisation/Visualisation using Seaborn/#or","text":"log into the Kabre jupyter server and then click on New and then New Python 3. We'll start with importing a set of libraries that will be useful for us and the gapminder data set. import numpy as np import pandas as pd import matplotlib.pyplot as plt import seaborn as sns sns.set(style=\"darkgrid\") The last line is a choice about how things look - you may want to leave that out. Now we'll read in the data. We will again use the gapminder data set but with the columns labelled differently. Please do not use the version you have used previously. The version is stored on a github repository which has been shortened using bit.ly. url=\"http://bit.ly/2PbVBcR\" #url=\"https://raw.githubusercontent.com/CODATA-RDA-DataScienceSchools/Materials/master/docs/DataSanJose2019/slides/Visualisation/gapminder.csv\" gapminder=pd.read_csv(url) So we are using pandas to read in the data set. The gapminder data set is a Data Frame .","title":"OR"},{"location":"DataSanJose2019/slides/Visualisation/Visualisation using Seaborn/#exploring-the-gapminder-data-set","text":"The gapminder data set is a set of socioeconomic data about populations, GDP per capita and expected life span for a large number of countries over a number of years. We can have a look at it using the head command. gapminder.head() You should get something like this. Unnamed: 0 country continent year lifeExp pop gdpPercap 0 1 Afghanistan Asia 1952 28.801 8425333 779.445314 1 2 Afghanistan Asia 1957 30.332 9240934 820.853030 2 3 Afghanistan Asia 1962 31.997 10267083 853.100710 3 4 Afghanistan Asia 1967 34.020 11537966 836.197138 4 5 Afghanistan Asia 1972 36.088 13079460 739.981106 So it is a combination of categorical data (countries and continents) and quantitative data (year, lifeExp etc.). It's also nice (though unrealistic) that it doesn't have missing values or malformed data e.g. Ireland is written sometimes as \"Ireland\" and sometimes \"ireland\" and sometimes \"Republic of Ireland\" or even \"Eire\"!! Dealing with those kinds of issues is not what we're going to focus on here. We can do a statistical summary of the numerical data using the describe function gapminder.describe() Unnamed: 0 year lifeExp pop gdpPercap count 1704.000000 1704.00000 1704.000000 1.704000e+03 1704.000000 mean 852.500000 1979.50000 59.474439 2.960121e+07 7215.327081 std 492.046746 17.26533 12.917107 1.061579e+08 9857.454543 min 1.000000 1952.00000 23.599000 6.001100e+04 241.165877 25% 426.750000 1965.75000 48.198000 2.793664e+06 1202.060309 50% 852.500000 1979.50000 60.712500 7.023596e+06 3531.846989 75% 1278.250000 1993.25000 70.845500 1.958522e+07 9325.462346 max 1704.000000 2007.00000 82.603000 1.318683e+09 113523.132900 One can find the names of the continents by executing the following. list(set(gapminder.continent)) We note that gapminder.continent gives us the list with the column corresponding to the continent entry. The set command converts the list into a set (which only has unique entries) and then list turns that back into a list again. We can list these entries alphabetically from the command sorted(list(set(gapminder.continent)))","title":"Exploring the gapminder data set"},{"location":"DataSanJose2019/slides/Visualisation/Visualisation using Seaborn/#exercise","text":"What does the function sorted do? Do the same for the countries. The gsapminder data set also presents lots of questions such as Is there a relationship between gdpPercap (roughly a measure of the average wealth of each person in a country) and their average life span? Is the average life span changing over time? How does picture change over different countries or comntinents? Visualisation allows us to explore all of this!","title":"Exercise"},{"location":"DataSanJose2019/slides/Visualisation/Visualisation using Seaborn/#getting-started-with-seaborn","text":"Let us start with doing box plots which count the number of entries that we have for each continent. sns.countplot(x=\"continent\", data=gapminder) You should get the folllowing. Note that generically seaborn generally looks like this. sns. (x= , y= , ... , data =< a data frame>) We use countplot here to just count entries and plot them as a box plot.","title":"Getting started with seaborn"},{"location":"DataSanJose2019/slides/Visualisation/Visualisation using Seaborn/#exercise_1","text":"What happens if we do the following? sns.countplot(x=\"Continent\", data=gapminder) What does that tell us?","title":"Exercise"},{"location":"DataSanJose2019/slides/Visualisation/Visualisation using Seaborn/#printing-out","text":"You can save a figure as a PNG or as a PDF then in the same cell as the command you run to plot use the savefig command. sns.countplot(x=\"continent\", data=gapminder) plt.savefig(\"Histogram.png\") plt.savefig(\"Histogram.pdf\")","title":"Printing out"},{"location":"DataSanJose2019/slides/Visualisation/Visualisation using Seaborn/#looking-at-1-d-distributions","text":"We can use the command catplot to just look at the distribution of life expenctancies. sns.catplot(y=\"lifeExp\", data=gapminder) You should get something like this. The points are jittered i.e. randomly moved in the horizontal axis to make things clearer. We can switch that off if we wish. sns.catplot(y=\"lifeExp\", data=gapminder,jitter=False) This scatterplot is not very informative! We can create a box plot of the data sns.boxplot(y=\"lifeExp\", data=gapminder) This should give the following.","title":"Looking at 1-d distributions"},{"location":"DataSanJose2019/slides/Visualisation/Visualisation using Seaborn/#exercise_2","text":"One can use another type of plot called a violin plot which tries to summarise the distribution better than a boxplot. The width of the violin plot represents how big the distribution is at that value. It is quite useful for picking out multi-modal (one with a distribution that has more than one peak). The command in seaborn is violinplot. Try and implement this for this data.","title":"Exercise"},{"location":"DataSanJose2019/slides/Visualisation/Visualisation using Seaborn/#diving-deeper-into-the-data","text":"Just looking at the life expectancy for all of the countries isn't very informative. The first thing we can do is ask how does this vary across continents. Seaborn does this easily by introducing an x-axis which is the continent. Again, let's try with just the points. sns.catplot(x=\"continent\", y=\"lifeExp\", data=gapminder)","title":"Diving deeper into the data"},{"location":"DataSanJose2019/slides/Visualisation/Visualisation using Seaborn/#exercise_3","text":"Repeat this using box plots (and violin plots if you wish). Repeat the above steps using GDP per capita (gdpPercap) instead of life expectancy. You can also try the swarmplot function as another way to represent this data. Can we just draw a distribution or a histogram? What about dividing it as continents? Yes! But we'll get to that in a bit.","title":"Exercise"},{"location":"DataSanJose2019/slides/Visualisation/Visualisation using Seaborn/#ordering","text":"Plotting the box plots with the continents in alphabetical order is quite easy. orderedContinents = sorted(list(set(gapminder.continent))) orderedContinents orderedContinents is a list with the continents ordered. sns.boxplot(x=\"continent\", y=\"lifeExp\", order=orderedContinents, data=gapminder) On the other hand we may want to order the box plots in ascending order of the medians of the life expectancy. This is more involved but is a good exercise in manipulating the data. #Create an empty dictionary medianLifeExps = {} # Loop through all the continents for val in gapminder.continent: # Create a new key which is the median life expectancy of that continent # gapminder[gapminder.continent == val] pulls out the continent in that loop # the .lifeExp.median() part then computes the median # of the remaining life expectancy data key = gapminder[gapminder.continent==val].lifeExp.median() # create a new entry in the dictionary with the continent as the value and the key # as the median. medianLifeExps[key] = val # Create a sorted list of the medians (in ascending order) sortedKeys = sorted(medianLifeExps) # Finally return the list of continents in that order orderedMedianContinents = [] for m in orderedMedians: orderedMedianContinents.append(medianLifeExps[m]) sns.boxplot(x=\"continent\", y=\"lifeExp\", order=orderedMedianContinents, data=gapminder)","title":"Ordering"},{"location":"DataSanJose2019/slides/Visualisation/Visualisation using Seaborn/#exercise_4","text":"Do the same plot for GDP per capita.","title":"Exercise"},{"location":"DataSanJose2019/slides/Visualisation/Visualisation using Seaborn/#line-and-scatter-plots","text":"Instead of having a categorical variable on the horizontal access we now do scatter and line plots. Let's start with the whole data set. sns.scatterplot(x=\"gdpPercap\",y=\"lifeExp\",data=gapminder) This is hard to grasp as a whole, so we'll just consider one country - China. We can select data corresponding to China by the following. gapminder[gapminder.country==\"China\"] sns.scatterplot(x=\"gdpPercap\",y=\"lifeExp\",data= gapminder[gapminder.country==\"China\"])","title":"Line and scatter plots"},{"location":"DataSanJose2019/slides/Visualisation/Visualisation using Seaborn/#exercise_5","text":"Do the same for your country - if it isn't listed in gapminder then pick another. A line plot works in the same way. It's possible to overlay these in the same cell. sns.lineplot(x=\"gdpPercap\",y=\"lifeExp\",data= gapminder[gapminder.country==\"China\"]) sns.scatterplot(x=\"gdpPercap\",y=\"lifeExp\",data= gapminder[gapminder.country==\"China\"])","title":"Exercise"},{"location":"DataSanJose2019/slides/Visualisation/Visualisation using Seaborn/#expressing-more-variables-with-different-attributes","text":"It is hard to make out the points from the lines. We can change the colour (color) of the points accordingly. sns.lineplot(x=\"gdpPercap\",y=\"lifeExp\",data= gapminder[gapminder.country==\"China\"]) sns.scatterplot(x=\"gdpPercap\",y=\"lifeExp\",color=\"red\",data= gapminder[gapminder.country==\"China\"]) We can use the colour of the points to represent a different column - e.g. the year. sns.lineplot(x=\"gdpPercap\",y=\"lifeExp\",data= gapminder[gapminder.country==\"China\"]) sns.scatterplot(x=\"gdpPercap\",y=\"lifeExp\",hue=\"year\", data= gapminder[gapminder.country==\"China\"]) The problem here is that only a certain number of years have been picked out. We need to tell seaborn how many years there are and how to set a palette of colours for this (the default palette has six colours). # Find the number of years (why only set?) n = len(set(gapminder.year)) sns.lineplot(x=\"gdpPercap\",y=\"lifeExp\",data= gapminder[gapminder.country==\"China\"]) # We use a rainbow-like palette but there are others. sns.scatterplot(x=\"gdpPercap\",y=\"lifeExp\",hue=\"year\",palette=sns.color_palette(\"rainbow_r\",n), data= gapminder[gapminder.country==\"China\"]) We can use the size of the point to represent an additional column - the population. n = len(set(gapminder.year)) sns.lineplot(x=\"gdpPercap\",y=\"lifeExp\",data= gapminder[gapminder.country==\"China\"]) sns.scatterplot(x=\"gdpPercap\",y=\"lifeExp\",hue=\"year\",size=\"pop\", palette=sns.color_palette(\"rainbow_r\",n), data= gapminder[gapminder.country==\"China\"]) The problem now is that there is too much detail in the legend - so we'll switch that off. n = len(set(gapminder.year)) sns.lineplot(x=\"gdpPercap\",y=\"lifeExp\",data= gapminder[gapminder.country==\"China\"]) sns.scatterplot(x=\"gdpPercap\",y=\"lifeExp\",hue=\"year\",size=\"pop\", palette=sns.color_palette(\"rainbow_r\",n), data= gapminder[gapminder.country==\"China\"], legend=False) How useful is adding these attributes?","title":"Expressing more variables with different attributes"},{"location":"DataSanJose2019/slides/Visualisation/Visualisation using Seaborn/#exercise_6","text":"Pick another country and try this out. Costa Rica is interesting. Does anybody have an explanation?","title":"Exercise"},{"location":"DataSanJose2019/slides/Visualisation/Visualisation using Seaborn/#summarising","text":"We will now examine how life expenctancy has varied over time. sns.lineplot(x=\"year\",y=\"lifeExp\",hue=\"country\",data= gapminder,legend=False) There are so many countries here I haven't even tried to construct a palette! Looking at this many countries are generally increasing but some are not following that trend. We could explore those outliers but here we will focus on trying to summarise what is going on (is a particular continent not going with the trend of increasing life span over time?) To do this we need to use another pandas command groupby which creates a new data frame for particular variables. Once we have created that new data frame we can then plot the data. # First create a new data frame which has the medians, by year and continent, of the life expectancy medianGapminder = gapminder.groupby(['continent','year']).lifeExp.median() # Now plot it sns.lineplot(x=\"year\",y=\"lifeExp\",hue=\"continent\",data= medianGapminder) What happened? The groupby command makes continent and year indices of the data (you can see this if you print out the data frame). Having created the data frame we need to reset the indices. # First create a new data frame which has the medians, by year and continent, of the life expectancy medianGapminder = gapminder.groupby(['continent','year']).lifeExp.median() # Now plot it sns.lineplot(x=\"year\",y=\"lifeExp\",hue=\"continent\",data= medianGapminder.reset_index())","title":"Summarising"},{"location":"DataSanJose2019/slides/Visualisation/Visualisation using Seaborn/#exercise_7","text":"Repeat this using the GDP per capita. Use a different statistical summary apart from the median.","title":"Exercise"},{"location":"DataSanJose2019/slides/Visualisation/Visualisation using Seaborn/#regression","text":"The line plots just \"join the dots\". It is more intesting to try and fit the data to a curve. We also want to do the fit and distinguish between the different continents. We can do this using the lmplot command. sns.lmplot(x=\"year\",y=\"lifeExp\",hue=\"continent\", data= medianGapminder.reset_index()) This does a simple linear regression. We can do more sophisticated types of fit, for example Loess (or Lowess). sns.lmplot(x=\"year\",y=\"lifeExp\",hue=\"continent\", lowess=True, data= medianGapminder.reset_index())","title":"Regression"},{"location":"DataSanJose2019/slides/Visualisation/Visualisation using Seaborn/#exercise_8","text":"Repeat the above using the GDP per capita.","title":"Exercise"},{"location":"DataSanJose2019/slides/Visualisation/Visualisation using Seaborn/#more-regression","text":"Now that we know how to fit curves through data with a number of different variables we can go back to the case of where we plotted the life expectancy against the GDP per capita. Instead of just doing a scatter plot we can now do regression (curve fitting) as function of the continent as well so we can see how the life expectancy varies between GDP per capita and the continent. sns.lmplot(x=\"gdpPercap\",y=\"lifeExp\",hue=\"continent\", lowess=True,data=gapminder) The problem here is that points are too large - we cannot see the trend. When you have many points make the point size smaller, indeed way smaller (someone described it as 'dust size') to see the trend better. Since Seaborn is based on Matplotlib we need to use a slightly different notation in the arguments to what was used previously. # scatter_kws is passed onto the underlying matplotlib plotting routine. sns.lmplot(x=\"gdpPercap\",y=\"lifeExp\",hue=\"continent\", lowess=True,data=gapminder,scatter_kws={\"s\":5}) The GDP per capita varies over a wide range and it would be good in the first instance to plot the x-axis on a logarithmic scale. Again since Seaborn is based on Matplotlib we need to use a slightly different notation to what was used previously. ax = sns.lmplot(x=\"gdpPercap\",y=\"lifeExp\",hue=\"continent\", lowess=True, data=gapminder,scatter_kws={\"s\":5}) ax.set(xscale=\"log\") We now get a much better spread of the data but it's still hard to see how the different continents are behaving. To do that we make use of facet plots . These are simply plots of different but related variables that are organised on the same screen for easy comparison. ax = sns.lmplot(x=\"gdpPercap\",y=\"lifeExp\",col=\"continent\", lowess=True, data=gapminder,scatter_kws={\"s\":5}) ax.set(xlim=(100,200000),xscale=\"log\") We note that the axes of all of these plots are the same so we can do a valid comparison. Still these plots are quite squashed as thy try and fit to the width of the page. Instead we can wrap them around. ax = sns.lmplot(x=\"gdpPercap\",y=\"lifeExp\",col=\"continent\", col_wrap=2, lowess=True, data=gapminder,scatter_kws={\"s\":5}) ax.set(xlim=(100,200000),xscale=\"log\") Finally, we can adjust the colour of the individual plots. ax = sns.lmplot(x=\"gdpPercap\",y=\"lifeExp\",col=\"continent\", hue=\"continent\", col_wrap=2, lowess=True, data=gapminder,scatter_kws={\"s\":5}) ax.set(xlim=(100,200000),xscale=\"log\")","title":"More regression"},{"location":"DataSanJose2019/slides/Visualisation/Visualisation using Seaborn/#exercise_9","text":"Do the same type of plots for life expectancy against year.","title":"Exercise"},{"location":"DataSanJose2019/slides/Visualisation/Visualisation using Seaborn/#distributions","text":"We can plot the distribution of a list of data (one column from a data frame) using a kernal density approach and/or a histogram. sns.distplot(gapminder.lifeExp) distplot only allows a single column from a data frame! You can also add the raw data into this plot as well (although this isn't very useful in this case as there's so much data). sns.distplot(gapminder.lifeExp,rug=True)","title":"Distributions"},{"location":"DataSanJose2019/slides/Visualisation/Visualisation using Seaborn/#exercise_10","text":"Do the same type of plot with the GDP per capita data. Again we would like to break this down in separate continents. Again we will make use of facet plots. lmplot is designed to create facet plots but distplot isn't so we need to use a specific function called FacetGrid to do this. In the call below we also adjust the height and aspect (the height/width ratio) of the figures. # Create a facet of the gapminder data based on the continents ordered alphabetically (orderedContinents) g = sns.FacetGrid(gapminder, row=\"continent\", row_order=orderedContinents, height=2, aspect=4) # Plot on the facets the distribution of the life expctancy data, but don't plot the histogram. g.map(sns.distplot, \"lifeExp\", hist=False) Finally the facet plot can also be used with just one facet! # Create a facet plot with one facet but colour on continent. g = sns.FacetGrid(gapminder, hue=\"continent\",height=2, aspect=4) # Plot the distributions with no histogram g.map(sns.distplot, \"lifeExp\", hist=False) # Give the colour scheme in a legend g.add_legend()","title":"Exercise"},{"location":"DataSanJose2019/slides/Visualisation/Visualisation using Seaborn/#exercise_11","text":"Do the same type of plot with the GDP per capita data (Longer) Select the data from the gapminder data set for a particular continent and now create facet plots for those countries.","title":"Exercise"},{"location":"DataSaoPaulo2018/","text":"Sao Paulo School of Research Data Science December 3 \u2013 14, 2018 ICTP-SAIFR, Sao Paulo, Brazil Background and purpose The goal of this workshop is to train researchers in Research Data Science (RDS). RDS refers to the principles and practice of Open Science and research data management and curation, the use of a range of data platforms and infrastructures, large scale analysis, statistics, visualization and modelling techniques, software development and data annotation. These are important tools for extracting useful information from data and these tools are useful in every research area. A 10-day workshop, organized by CODATA, RDA, ICTP and SAIFR, was conducted at the ICTP-SAIFR, Sao Paulo to introduce participants to the skills of RDS. Materials for the 2018 School of Research Data Science in Sao Paulo Day 1 - Introduction, Open Science , UNIX Shell Day 2 - Version Control with Git , Introduction to R Day 3 - Introduction to R , Reports Knitr Day 4 - Data Visualization Day 5 - Research Data Management , Data Management Plans Day 6 - Open Science , Information Security Day 7 - Overview of Machine Learning Day 8 - Artificial Neural Networks Day 9 - Computational Infrastructures - Lecture 1 , Lecture 2 , Lecture 3 , Lecture 4 Day 10 - Computational Infrastructures Wrap-Up - Lecture 5 , Lecture 6 School Close Out","title":"Sao Paulo School of Research Data Science"},{"location":"DataSaoPaulo2018/#sao-paulo-school-of-research-data-science","text":"December 3 \u2013 14, 2018 ICTP-SAIFR, Sao Paulo, Brazil","title":"Sao Paulo School of Research Data Science"},{"location":"DataSaoPaulo2018/#background-and-purpose","text":"The goal of this workshop is to train researchers in Research Data Science (RDS). RDS refers to the principles and practice of Open Science and research data management and curation, the use of a range of data platforms and infrastructures, large scale analysis, statistics, visualization and modelling techniques, software development and data annotation. These are important tools for extracting useful information from data and these tools are useful in every research area. A 10-day workshop, organized by CODATA, RDA, ICTP and SAIFR, was conducted at the ICTP-SAIFR, Sao Paulo to introduce participants to the skills of RDS.","title":"Background and purpose"},{"location":"DataSaoPaulo2018/#materials-for-the-2018-school-of-research-data-science-in-sao-paulo","text":"Day 1 - Introduction, Open Science , UNIX Shell Day 2 - Version Control with Git , Introduction to R Day 3 - Introduction to R , Reports Knitr Day 4 - Data Visualization Day 5 - Research Data Management , Data Management Plans Day 6 - Open Science , Information Security Day 7 - Overview of Machine Learning Day 8 - Artificial Neural Networks Day 9 - Computational Infrastructures - Lecture 1 , Lecture 2 , Lecture 3 , Lecture 4 Day 10 - Computational Infrastructures Wrap-Up - Lecture 5 , Lecture 6 School Close Out","title":"Materials for the 2018 School of Research Data Science in Sao Paulo"},{"location":"DataSaoPaulo2018/word_clouds/Readme/","text":"Code and instructions to create the word clouds can be found in here","title":"Readme"},{"location":"DataTrieste2019/","text":"Trieste School of Research Data Science 5-16 August, 2019 ICTP, Trieste, Italy Background and purpose The goal of this workshop is to train researchers in Research Data Science (RDS). RDS refers to the principles and practice of Open Science and research data management and curation, the use of a range of data platforms and infrastructures, large scale analysis, statistics, visualization and modelling techniques, software development and data annotation. These are important tools for extracting useful information from data and these tools are useful in every research area. A 10-day workshop, organized by CODATA, RDA and ICTP, was conducted at the ICTP, Trieste to introduce participants to the skills of RDS. Materials for the 2019 School of Research Data Science in Trieste Day 1 - Introduction Open Science UNIX Shell Day 2 - Version Control with Git , Introduction to R Day 3 - Introduction to R Day 4 - Data Visualization Day 5 - Research Data Management , Data Management Plans Day 6 - Open Science , Information Security Day 7 - Overview of Machine Learning Day 8 - Artificial Neural Networks Day 9 - Computational Infrastructures - Lecture 1 , Lecture 2 , Lecture 3 , Lecture 4 Day 10 - Computational Infrastructures Wrap-Up - Lecture 5 , Lecture 6 School Close Out","title":"Trieste School of Research Data Science"},{"location":"DataTrieste2019/#trieste-school-of-research-data-science","text":"5-16 August, 2019 ICTP, Trieste, Italy","title":"Trieste School of Research Data Science"},{"location":"DataTrieste2019/#background-and-purpose","text":"The goal of this workshop is to train researchers in Research Data Science (RDS). RDS refers to the principles and practice of Open Science and research data management and curation, the use of a range of data platforms and infrastructures, large scale analysis, statistics, visualization and modelling techniques, software development and data annotation. These are important tools for extracting useful information from data and these tools are useful in every research area. A 10-day workshop, organized by CODATA, RDA and ICTP, was conducted at the ICTP, Trieste to introduce participants to the skills of RDS.","title":"Background and purpose"},{"location":"DataTrieste2019/#materials-for-the-2019-school-of-research-data-science-in-trieste","text":"Day 1 - Introduction Open Science UNIX Shell Day 2 - Version Control with Git , Introduction to R Day 3 - Introduction to R Day 4 - Data Visualization Day 5 - Research Data Management , Data Management Plans Day 6 - Open Science , Information Security Day 7 - Overview of Machine Learning Day 8 - Artificial Neural Networks Day 9 - Computational Infrastructures - Lecture 1 , Lecture 2 , Lecture 3 , Lecture 4 Day 10 - Computational Infrastructures Wrap-Up - Lecture 5 , Lecture 6 School Close Out","title":"Materials for the 2019 School of Research Data Science in Trieste"}]}